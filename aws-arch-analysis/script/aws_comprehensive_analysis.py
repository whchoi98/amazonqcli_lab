#!/usr/bin/env python3
"""
AWS ê³„ì • ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì: Amazon Q CLI
ë²„ì „: 2.0 (Python ë³€í™˜)
ìƒì„±ì¼: 2025-06-25
"""

import os
import sys
import json
import subprocess
import time
from datetime import datetime
from pathlib import Path
import shutil
from typing import Dict, List, Optional, Tuple

# ìƒ‰ìƒ ì •ì˜
class Colors:
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    PURPLE = '\033[0;35m'
    CYAN = '\033[0;36m'
    NC = '\033[0m'  # No Color

class Logger:
    """ë¡œê¹… ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    
    @staticmethod
    def info(message: str):
        print(f"{Colors.BLUE}[INFO]{Colors.NC} {message}")
    
    @staticmethod
    def success(message: str):
        print(f"{Colors.GREEN}[SUCCESS]{Colors.NC} {message}")
    
    @staticmethod
    def warning(message: str):
        print(f"{Colors.YELLOW}[WARNING]{Colors.NC} {message}")
    
    @staticmethod
    def error(message: str):
        print(f"{Colors.RED}[ERROR]{Colors.NC} {message}")
    
    @staticmethod
    def step(message: str):
        print(f"{Colors.PURPLE}[STEP]{Colors.NC} {message}")

class ProgressBar:
    """ì§„í–‰ë¥  í‘œì‹œ í´ë˜ìŠ¤"""
    
    @staticmethod
    def show_progress(current: int, total: int, desc: str):
        percent = (current * 100) // total
        bar_length = 50
        filled_length = (percent * bar_length) // 100
        
        bar = "â–ˆ" * filled_length + "â–‘" * (bar_length - filled_length)
        print(f"\r{Colors.CYAN}[{percent:3d}%]{Colors.NC} [{bar}] {desc}", end="")
        
        if current == total:
            print()

class AWSAnalyzer:
    """AWS ë¦¬ì†ŒìŠ¤ ë¶„ì„ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.start_time = time.time()
        self.script_dir = Path(__file__).parent
        self.report_dir = self.script_dir.parent / "report" / "comprehensive-analysis"
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.backup_dir = self.script_dir.parent / "report" / f"backup_{self.timestamp}"
        
        # AWS ì •ë³´
        self.aws_account_id = ""
        self.aws_region = ""
        
        # ë¶„ì„ ê²°ê³¼
        self.analysis_results = {}
        
    def print_header(self):
        """í—¤ë” ì¶œë ¥"""
        print(f"{Colors.CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—{Colors.NC}")
        print(f"{Colors.CYAN}â•‘                AWS ê³„ì • ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±ê¸°                â•‘{Colors.NC}")
        print(f"{Colors.CYAN}â•‘                     ìë™í™” ìŠ¤í¬ë¦½íŠ¸ v2.0                      â•‘{Colors.NC}")
        print(f"{Colors.CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.NC}")
        print()
        
    def validate_environment(self) -> bool:
        """í™˜ê²½ ê²€ì¦"""
        Logger.step("Phase 1: í™˜ê²½ ì¤€ë¹„ ë° ê²€ì¦")
        ProgressBar.show_progress(1, 10, "í™˜ê²½ ê²€ì¦ ì¤‘...")
        
        # í•„ìˆ˜ ë„êµ¬ í™•ì¸
        required_tools = ['steampipe', 'aws', 'python3']
        for tool in required_tools:
            if not shutil.which(tool):
                Logger.error(f"{tool}ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
        
        # AWS ìê²© ì¦ëª… í™•ì¸
        try:
            result = subprocess.run(['aws', 'sts', 'get-caller-identity'], 
                                  capture_output=True, text=True, check=True)
            caller_identity = json.loads(result.stdout)
            self.aws_account_id = caller_identity.get('Account', '')
        except subprocess.CalledProcessError:
            Logger.error("AWS ìê²© ì¦ëª…ì´ êµ¬ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        # AWS ë¦¬ì „ í™•ì¸
        try:
            result = subprocess.run(['aws', 'configure', 'get', 'region'], 
                                  capture_output=True, text=True)
            self.aws_region = result.stdout.strip() or "ap-northeast-2"
        except subprocess.CalledProcessError:
            self.aws_region = "ap-northeast-2"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.report_dir.mkdir(parents=True, exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        Logger.success("í™˜ê²½ ê²€ì¦ ì™„ë£Œ")
        Logger.info(f"ë¶„ì„ ì‹œì‘ ì‹œê°„: {datetime.now()}")
        Logger.info(f"ë³´ê³ ì„œ ì €ì¥ ìœ„ì¹˜: {self.report_dir}")
        
        return True
    
    def backup_existing_reports(self):
        """ê¸°ì¡´ ë³´ê³ ì„œ ë°±ì—…"""
        Logger.step("Phase 2: ê¸°ì¡´ ë³´ê³ ì„œ ë°±ì—…")
        ProgressBar.show_progress(2, 10, "ê¸°ì¡´ ë³´ê³ ì„œ ë°±ì—… ì¤‘...")
        
        if self.report_dir.exists() and any(self.report_dir.iterdir()):
            try:
                for item in self.report_dir.iterdir():
                    if item.is_file():
                        shutil.copy2(item, self.backup_dir)
                    elif item.is_dir():
                        shutil.copytree(item, self.backup_dir / item.name, dirs_exist_ok=True)
                Logger.success(f"ê¸°ì¡´ ë³´ê³ ì„œë¥¼ {self.backup_dir}ì— ë°±ì—…í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                Logger.warning(f"ë°±ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            Logger.info("ë°±ì—…í•  ê¸°ì¡´ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def collect_aws_data(self):
        """AWS ë°ì´í„° ìˆ˜ì§‘"""
        Logger.step("Phase 3: AWS ë°ì´í„° ìˆ˜ì§‘")
        ProgressBar.show_progress(3, 10, "AWS ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        Logger.info(f"AWS ê³„ì • ID: {self.aws_account_id}")
        Logger.info(f"AWS ë¦¬ì „: {self.aws_region}")
        
        # ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½
        os.chdir(self.report_dir)
        
        # Steampipe ì¿¼ë¦¬ ì‹¤í–‰
        queries = {
            'vpc_analysis.json': """
                SELECT 
                    vpc_id,
                    cidr_block,
                    state,
                    is_default,
                    tags->>'Name' as name,
                    tags
                FROM aws_vpc 
                ORDER BY vpc_id;
            """,
            'subnet_analysis.json': """
                SELECT 
                    subnet_id,
                    vpc_id,
                    cidr_block,
                    availability_zone,
                    map_public_ip_on_launch,
                    state,
                    tags->>'Name' as name
                FROM aws_vpc_subnet 
                ORDER BY vpc_id, availability_zone;
            """,
            'ec2_analysis.json': """
                SELECT 
                    instance_id,
                    instance_type,
                    instance_state,
                    vpc_id,
                    subnet_id,
                    private_ip_address,
                    public_ip_address,
                    placement_availability_zone as availability_zone,
                    launch_time,
                    tags->>'Name' as name,
                    platform,
                    architecture,
                    root_device_type,
                    tags
                FROM aws_ec2_instance 
                ORDER BY vpc_id, instance_id;
            """,
            'security_groups_analysis.json': """
                SELECT 
                    group_id,
                    group_name,
                    description,
                    vpc_id,
                    tags->>'Name' as name,
                    tags
                FROM aws_vpc_security_group 
                ORDER BY vpc_id, group_name;
            """,
            'rds_analysis.json': """
                SELECT 
                    db_instance_identifier,
                    class,
                    engine,
                    engine_version,
                    status,
                    allocated_storage,
                    storage_type,
                    multi_az,
                    publicly_accessible,
                    vpc_id,
                    db_subnet_group_name,
                    availability_zone,
                    backup_retention_period,
                    storage_encrypted,
                    tags
                FROM aws_rds_db_instance;
            """,
            'eks_analysis.json': """
                SELECT 
                    name,
                    status,
                    version,
                    platform_version,
                    endpoint,
                    created_at,
                    role_arn,
                    resources_vpc_config,
                    logging,
                    tags
                FROM aws_eks_cluster;
            """,
            'elasticache_analysis.json': """
                SELECT 
                    cache_cluster_id,
                    cache_node_type,
                    engine,
                    engine_version,
                    cache_cluster_status,
                    num_cache_nodes,
                    preferred_availability_zone,
                    cache_subnet_group_name,
                    security_groups,
                    tags
                FROM aws_elasticache_cluster;
            """,
            's3_analysis.json': """
                SELECT 
                    name,
                    region,
                    creation_date,
                    versioning_enabled,
                    server_side_encryption_configuration,
                    logging,
                    tags
                FROM aws_s3_bucket;
            """,
            'cloudformation_analysis.json': """
                SELECT 
                    name,
                    status,
                    creation_time,
                    last_updated_time,
                    description,
                    capabilities,
                    parameters,
                    outputs,
                    tags
                FROM aws_cloudformation_stack
                ORDER BY creation_time DESC;
            """,
            'cost_analysis.json': """
                SELECT 
                    service,
                    sum(unblended_cost_amount) as total_cost,
                    count(*) as days_count
                FROM aws_cost_by_service_daily 
                WHERE period_start >= current_date - interval '30 days'
                GROUP BY service
                ORDER BY total_cost DESC;
            """
        }
        
        for output_file, query in queries.items():
            Logger.info(f"{output_file.replace('_analysis.json', '').replace('.json', '')} ë¶„ì„ ì¤‘...")
            try:
                result = subprocess.run(
                    ['steampipe', 'query', query, '--output', 'json'],
                    capture_output=True, text=True, check=True
                )
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(result.stdout)
            except subprocess.CalledProcessError as e:
                Logger.warning(f"{output_file} ìƒì„± ì‹¤íŒ¨: {e}")
                # ë¹ˆ JSON ë°°ì—´ ìƒì„±
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write('[]')
        
        Logger.success("AWS ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
    
    def analyze_collected_data(self):
        """ìˆ˜ì§‘ëœ ë°ì´í„° ë¶„ì„"""
        Logger.step("Phase 4: ë¶„ì„ ë°ì´í„° ì²˜ë¦¬")
        ProgressBar.show_progress(4, 10, "ìˆ˜ì§‘ëœ ë°ì´í„° ë¶„ì„ ì¤‘...")
        
        # JSON íŒŒì¼ë“¤ ë¡œë“œ ë° ë¶„ì„
        try:
            with open('vpc_analysis.json', 'r') as f:
                vpc_data = json.load(f)
            with open('ec2_analysis.json', 'r') as f:
                ec2_data = json.load(f)
            with open('security_groups_analysis.json', 'r') as f:
                sg_data = json.load(f)
            with open('cost_analysis.json', 'r') as f:
                cost_data = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            Logger.warning(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            vpc_data = ec2_data = sg_data = cost_data = []
        
        # í†µê³„ ê³„ì‚°
        self.analysis_results = {
            'vpc_count': len(vpc_data),
            'ec2_count': len(ec2_data),
            'security_group_count': len(sg_data),
            'total_cost': sum(float(item.get('total_cost', 0)) for item in cost_data)
        }
        
        Logger.info("ë°œê²¬ëœ ë¦¬ì†ŒìŠ¤:")
        Logger.info(f"  - VPC: {self.analysis_results['vpc_count']}ê°œ")
        Logger.info(f"  - EC2 ì¸ìŠ¤í„´ìŠ¤: {self.analysis_results['ec2_count']}ê°œ")
        Logger.info(f"  - ë³´ì•ˆ ê·¸ë£¹: {self.analysis_results['security_group_count']}ê°œ")
        Logger.info(f"  - ì›”ê°„ ì´ ë¹„ìš©: ${self.analysis_results['total_cost']:.2f}")
        
        Logger.success("ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        self.print_header()
        
        if not self.validate_environment():
            sys.exit(1)
        
        self.backup_existing_reports()
        self.collect_aws_data()
        self.analyze_collected_data()
        
        # ë³´ê³ ì„œ ìƒì„± ëª¨ë“ˆë“¤ í˜¸ì¶œ
        from report_generators import MarkdownReportGenerator
        from html_generator import HTMLConverter, DashboardGenerator
        
        # Phase 5: Markdown ë³´ê³ ì„œ ìƒì„±
        Logger.step("Phase 5: Markdown ë³´ê³ ì„œ ìƒì„±")
        ProgressBar.show_progress(5, 10, "ë³´ê³ ì„œ í…œí”Œë¦¿ ìƒì„± ì¤‘...")
        
        markdown_generator = MarkdownReportGenerator(
            self.aws_account_id, 
            self.aws_region, 
            self.analysis_results
        )
        markdown_generator.generate_all_reports()
        
        Logger.success("Markdown ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        
        # Phase 6: HTML ë³€í™˜
        Logger.step("Phase 6: HTML ë³€í™˜")
        ProgressBar.show_progress(6, 10, "HTML ë³€í™˜ ì¤‘...")
        
        html_converter = HTMLConverter(self.aws_account_id)
        html_converter.convert_all_markdown_files()
        
        Logger.success("HTML ë³€í™˜ ì™„ë£Œ")
        
        # Phase 7: ë©”ì¸ ëŒ€ì‹œë³´ë“œ ìƒì„±
        Logger.step("Phase 7: ë©”ì¸ ëŒ€ì‹œë³´ë“œ ìƒì„±")
        ProgressBar.show_progress(7, 10, "ë©”ì¸ ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘...")
        
        dashboard_generator = DashboardGenerator(
            self.aws_account_id,
            self.aws_region,
            self.analysis_results
        )
        dashboard_generator.generate_dashboard()
        
        Logger.success("ë©”ì¸ ëŒ€ì‹œë³´ë“œ ìƒì„± ì™„ë£Œ")
        
        # Phase 8-10: ìµœì¢… ì²˜ë¦¬
        self.finalize_analysis()
    
    def finalize_analysis(self):
        """ë¶„ì„ ì™„ë£Œ ì²˜ë¦¬"""
        Logger.step("Phase 8: í’ˆì§ˆ ê²€ì¦")
        ProgressBar.show_progress(8, 10, "ìƒì„±ëœ íŒŒì¼ ê²€ì¦ ì¤‘...")
        
        # í•„ìˆ˜ íŒŒì¼ í™•ì¸
        required_files = [
            "01-executive-summary.md", "01-executive-summary.html",
            "02-networking-analysis.md", "02-networking-analysis.html",
            "07-cost-optimization.md", "07-cost-optimization.html",
            "index.html"
        ]
        
        missing_files = [f for f in required_files if not (self.report_dir / f).exists()]
        
        if not missing_files:
            Logger.success("ëª¨ë“  í•„ìˆ˜ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            Logger.warning(f"ëˆ„ë½ëœ íŒŒì¼: {', '.join(missing_files)}")
        
        Logger.step("Phase 9: ìµœì¢… ì •ë¦¬")
        ProgressBar.show_progress(9, 10, "ìµœì¢… ì •ë¦¬ ì¤‘...")
        
        # ìš”ì•½ ì •ë³´ ìƒì„±
        summary_content = f"""AWS ê³„ì • ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ

ìƒì„± ì¼ì‹œ: {datetime.now()}
AWS ê³„ì • ID: {self.aws_account_id}
AWS ë¦¬ì „: {self.aws_region}

ë°œê²¬ëœ ë¦¬ì†ŒìŠ¤:
- VPC: {self.analysis_results['vpc_count']}ê°œ
- EC2 ì¸ìŠ¤í„´ìŠ¤: {self.analysis_results['ec2_count']}ê°œ
- ë³´ì•ˆ ê·¸ë£¹: {self.analysis_results['security_group_count']}ê°œ
- ì›”ê°„ ì´ ë¹„ìš©: ${self.analysis_results['total_cost']:.2f}

ìƒì„±ëœ íŒŒì¼:
- Markdown ë³´ê³ ì„œ: 10ê°œ
- HTML ë³´ê³ ì„œ: 10ê°œ
- ë©”ì¸ ëŒ€ì‹œë³´ë“œ: index.html
- ë¶„ì„ ë°ì´í„°: JSON íŒŒì¼ë“¤

ë‹¤ìŒ ë‹¨ê³„:
1. index.htmlì„ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ ëŒ€ì‹œë³´ë“œ í™•ì¸
2. ê° ì˜ì—­ë³„ ìƒì„¸ ë³´ê³ ì„œ ê²€í† 
3. ê¶Œì¥ì‚¬í•­ì— ë”°ë¥¸ ì•¡ì…˜ ì•„ì´í…œ ì‹¤í–‰
"""
        
        with open(self.report_dir / "analysis_summary.txt", 'w', encoding='utf-8') as f:
            f.write(summary_content)
        
        Logger.success("ë¶„ì„ ìš”ì•½ íŒŒì¼ ìƒì„± ì™„ë£Œ")
        
        Logger.step("Phase 10: ì™„ë£Œ")
        ProgressBar.show_progress(10, 10, "ë¶„ì„ ì™„ë£Œ!")
        
        # ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥
        self.print_completion_message()
    
    def print_completion_message(self):
        """ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥"""
        end_time = time.time()
        execution_time = int(end_time - self.start_time)
        minutes = execution_time // 60
        seconds = execution_time % 60
        
        print()
        print(f"{Colors.GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—{Colors.NC}")
        print(f"{Colors.GREEN}â•‘                    ğŸ‰ ë¶„ì„ ì™„ë£Œ! ğŸ‰                          â•‘{Colors.NC}")
        print(f"{Colors.GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.NC}")
        print()
        
        Logger.success("AWS ê³„ì • ì¢…í•© ë¶„ì„ ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print()
        print(f"{Colors.CYAN}ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:{Colors.NC}")
        print(f"  â€¢ VPC: {self.analysis_results['vpc_count']}ê°œ")
        print(f"  â€¢ EC2 ì¸ìŠ¤í„´ìŠ¤: {self.analysis_results['ec2_count']}ê°œ")
        print(f"  â€¢ ë³´ì•ˆ ê·¸ë£¹: {self.analysis_results['security_group_count']}ê°œ")
        print(f"  â€¢ ì›”ê°„ ì´ ë¹„ìš©: ${self.analysis_results['total_cost']:.2f}")
        print()
        print(f"{Colors.CYAN}ğŸ“ ìƒì„±ëœ íŒŒì¼:{Colors.NC}")
        print(f"  â€¢ ë³´ê³ ì„œ ìœ„ì¹˜: {self.report_dir}")
        print(f"  â€¢ ë©”ì¸ ëŒ€ì‹œë³´ë“œ: {self.report_dir}/index.html")
        print(f"  â€¢ Markdown ë³´ê³ ì„œ: 10ê°œ")
        print(f"  â€¢ HTML ë³´ê³ ì„œ: 10ê°œ")
        print()
        print(f"{Colors.CYAN}â±ï¸ ì‹¤í–‰ ì‹œê°„:{Colors.NC} {minutes}ë¶„ {seconds}ì´ˆ")
        print()
        print(f"{Colors.YELLOW}ğŸš€ ë‹¤ìŒ ë‹¨ê³„:{Colors.NC}")
        print("  1. ë¸Œë¼ìš°ì €ì—ì„œ index.html ì—´ê¸°")
        print("  2. ê° ì˜ì—­ë³„ ìƒì„¸ ë³´ê³ ì„œ ê²€í† ")
        print("  3. ê¶Œì¥ì‚¬í•­ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½")
        print()
        print(f"{Colors.BLUE}ğŸ’¡ ë³´ê³ ì„œ í™•ì¸ ë°©ë²•:{Colors.NC}")
        print(f"  â€¢ ì›¹ ëŒ€ì‹œë³´ë“œ: file://{self.report_dir}/index.html")
        print(f"  â€¢ Markdown í™•ì¸: glow {self.report_dir}/01-executive-summary.md")
        print()
        
        if self.backup_dir.exists() and any(self.backup_dir.iterdir()):
            print(f"{Colors.CYAN}ğŸ’¾ ë°±ì—… ì •ë³´:{Colors.NC}")
            print(f"  â€¢ ì´ì „ ë³´ê³ ì„œ ë°±ì—…: {self.backup_dir}")
            print()
        
        Logger.success("ë¶„ì„ ì™„ë£Œ! ğŸŠ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    analyzer = AWSAnalyzer()
    analyzer.run_analysis()

if __name__ == "__main__":
    main()
