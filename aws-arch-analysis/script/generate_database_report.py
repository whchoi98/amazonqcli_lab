#!/usr/bin/env python3
"""
ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (Python ë²„ì „)
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional

class DatabaseReportGenerator:
    def __init__(self, report_dir: str = "/home/ec2-user/amazonqcli_lab/aws-arch-analysis/report"):
        self.report_dir = Path(report_dir)
        self.report_dir.mkdir(parents=True, exist_ok=True)

    def load_json_file(self, filename: str) -> Optional[List[Dict[str, Any]]]:
        """JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        file_path = self.report_dir / filename
        try:
            if file_path.exists() and file_path.stat().st_size > 0:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict) and 'rows' in data:
                        return data['rows']
                    elif isinstance(data, list):
                        return data
                    return []
        except (json.JSONDecodeError, IOError) as e:
            print(f"Warning: Failed to load {filename}: {e}")
        return None

    def write_rds_analysis(self, report_file, rds_data: Optional[List]) -> None:
        """RDS ë¶„ì„ ì„¹ì…˜ì„ ì‘ì„±í•©ë‹ˆë‹¤."""
        report_file.write("## ğŸ—„ï¸ RDS ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©\n\n")
        
        if not rds_data:
            report_file.write("RDS ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n")
            return
        
        total_instances = len(rds_data)
        multi_az_count = len([r for r in rds_data if r.get('multi_az', False)])
        encrypted_count = len([r for r in rds_data if r.get('storage_encrypted', False)])
        
        report_file.write(f"**ì´ RDS ì¸ìŠ¤í„´ìŠ¤:** {total_instances}ê°œ\n")
        report_file.write(f"- **Multi-AZ ë°°í¬:** {multi_az_count}ê°œ\n")
        report_file.write(f"- **ì•”í˜¸í™”ëœ ì¸ìŠ¤í„´ìŠ¤:** {encrypted_count}ê°œ\n\n")
        
        # ì—”ì§„ë³„ ë¶„í¬
        engine_stats = {}
        for instance in rds_data:
            engine = instance.get('engine', 'unknown')
            if engine not in engine_stats:
                engine_stats[engine] = 0
            engine_stats[engine] += 1
        
        report_file.write("### ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§„ë³„ ë¶„í¬\n")
        report_file.write("| ì—”ì§„ | ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ |\n")
        report_file.write("|------|-------------|\n")
        for engine, count in engine_stats.items():
            report_file.write(f"| {engine} | {count} |\n")
        
        # ìƒì„¸ ëª©ë¡
        report_file.write("\n### RDS ì¸ìŠ¤í„´ìŠ¤ ìƒì„¸ ëª©ë¡\n")
        report_file.write("| ì¸ìŠ¤í„´ìŠ¤ ID | ì—”ì§„ | í´ë˜ìŠ¤ | ìƒíƒœ | Multi-AZ | ì•”í˜¸í™” | ë°±ì—… ë³´ì¡´ |\n")
        report_file.write("|-------------|------|--------|------|----------|--------|------------|\n")
        
        for instance in rds_data:
            db_id = instance.get('db_instance_identifier', 'N/A')
            engine = instance.get('engine', 'N/A')
            db_class = instance.get('db_instance_class', 'N/A')
            status = instance.get('db_instance_status', 'N/A')
            multi_az = 'ì˜ˆ' if instance.get('multi_az', False) else 'ì•„ë‹ˆì˜¤'
            encrypted = 'ì˜ˆ' if instance.get('storage_encrypted', False) else 'ì•„ë‹ˆì˜¤'
            backup_retention = f"{instance.get('backup_retention_period', 0)}ì¼"
            
            report_file.write(f"| {db_id} | {engine} | {db_class} | {status} | {multi_az} | {encrypted} | {backup_retention} |\n")
        
        if total_instances > 10:
            report_file.write(f"... ë° {total_instances - 10}ê°œ ì¶”ê°€ ì¸ìŠ¤í„´ìŠ¤\n")
        
        report_file.write("\n")

    def write_dynamodb_analysis(self, report_file, dynamodb_data: Optional[List]) -> None:
        """DynamoDB ë¶„ì„ ì„¹ì…˜ì„ ì‘ì„±í•©ë‹ˆë‹¤."""
        report_file.write("## âš¡ DynamoDB í…Œì´ë¸” í˜„í™©\n\n")
        
        if not dynamodb_data:
            report_file.write("DynamoDB í…Œì´ë¸” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n")
            return
        
        total_tables = len(dynamodb_data)
        on_demand_count = len([t for t in dynamodb_data if t.get('billing_mode_summary', {}).get('billing_mode') == 'PAY_PER_REQUEST'])
        provisioned_count = total_tables - on_demand_count
        
        report_file.write(f"**ì´ DynamoDB í…Œì´ë¸”:** {total_tables}ê°œ\n")
        report_file.write(f"- **ì˜¨ë””ë§¨ë“œ ëª¨ë“œ:** {on_demand_count}ê°œ\n")
        report_file.write(f"- **í”„ë¡œë¹„ì €ë‹ ëª¨ë“œ:** {provisioned_count}ê°œ\n\n")
        
        # ìƒì„¸ ëª©ë¡
        report_file.write("### DynamoDB í…Œì´ë¸” ìƒì„¸ ëª©ë¡\n")
        report_file.write("| í…Œì´ë¸” ì´ë¦„ | ìƒíƒœ | ë¹Œë§ ëª¨ë“œ | ìƒì„±ì¼ | GSI ìˆ˜ |\n")
        report_file.write("|-------------|------|-----------|--------|--------|\n")
        
        for table in dynamodb_data:
            table_name = table.get('table_name', 'N/A')
            status = table.get('table_status', 'N/A')
            billing_mode = table.get('billing_mode_summary', {}).get('billing_mode', 'N/A')
            creation_date = table.get('creation_date_time', 'N/A')[:10] if table.get('creation_date_time') else 'N/A'
            gsi_count = len(table.get('global_secondary_indexes', []))
            
            report_file.write(f"| {table_name} | {status} | {billing_mode} | {creation_date} | {gsi_count} |\n")
        
        if total_tables > 10:
            report_file.write(f"... ë° {total_tables - 10}ê°œ ì¶”ê°€ í…Œì´ë¸”\n")
        
        report_file.write("\n")

    def write_elasticache_analysis(self, report_file, elasticache_data: Optional[List]) -> None:
        """ElastiCache ë¶„ì„ ì„¹ì…˜ì„ ì‘ì„±í•©ë‹ˆë‹¤."""
        report_file.write("## ğŸš€ ElastiCache í´ëŸ¬ìŠ¤í„° í˜„í™©\n\n")
        
        if not elasticache_data:
            report_file.write("ElastiCache í´ëŸ¬ìŠ¤í„° ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n")
            return
        
        total_clusters = len(elasticache_data)
        redis_count = len([c for c in elasticache_data if c.get('engine') == 'redis'])
        memcached_count = len([c for c in elasticache_data if c.get('engine') == 'memcached'])
        
        report_file.write(f"**ì´ ElastiCache í´ëŸ¬ìŠ¤í„°:** {total_clusters}ê°œ\n")
        report_file.write(f"- **Redis:** {redis_count}ê°œ\n")
        report_file.write(f"- **Memcached:** {memcached_count}ê°œ\n\n")
        
        # ìƒì„¸ ëª©ë¡
        report_file.write("### ElastiCache í´ëŸ¬ìŠ¤í„° ìƒì„¸ ëª©ë¡\n")
        report_file.write("| í´ëŸ¬ìŠ¤í„° ID | ì—”ì§„ | ë…¸ë“œ íƒ€ì… | ìƒíƒœ | ë…¸ë“œ ìˆ˜ | ì•”í˜¸í™” |\n")
        report_file.write("|-------------|------|-----------|------|---------|--------|\n")
        
        for cluster in elasticache_data:
            cluster_id = cluster.get('cache_cluster_id', 'N/A')
            engine = cluster.get('engine', 'N/A')
            node_type = cluster.get('cache_node_type', 'N/A')
            status = cluster.get('cache_cluster_status', 'N/A')
            num_nodes = cluster.get('num_cache_nodes', 0)
            encrypted = 'ì˜ˆ' if cluster.get('at_rest_encryption_enabled', False) else 'ì•„ë‹ˆì˜¤'
            
            report_file.write(f"| {cluster_id} | {engine} | {node_type} | {status} | {num_nodes} | {encrypted} |\n")
        
        if total_clusters > 10:
            report_file.write(f"... ë° {total_clusters - 10}ê°œ ì¶”ê°€ í´ëŸ¬ìŠ¤í„°\n")
        
        report_file.write("\n")

    def write_database_recommendations(self, report_file, rds_data: Optional[List], dynamodb_data: Optional[List]) -> None:
        """ë°ì´í„°ë² ì´ìŠ¤ ê¶Œì¥ì‚¬í•­ ì„¹ì…˜ì„ ì‘ì„±í•©ë‹ˆë‹¤."""
        report_file.write("## ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ê¶Œì¥ì‚¬í•­\n\n")
        
        report_file.write("### ğŸ”´ ë†’ì€ ìš°ì„ ìˆœìœ„\n")
        
        recommendations = []
        
        # RDS ê´€ë ¨ ê¶Œì¥ì‚¬í•­
        if rds_data:
            unencrypted_rds = [r for r in rds_data if not r.get('storage_encrypted', False)]
            single_az_rds = [r for r in rds_data if not r.get('multi_az', False)]
            
            if unencrypted_rds:
                recommendations.append(f"**RDS ì•”í˜¸í™”**: {len(unencrypted_rds)}ê°œì˜ ì•”í˜¸í™”ë˜ì§€ ì•Šì€ RDS ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ë³´ì•ˆì„ ìœ„í•´ ì•”í˜¸í™”ë¥¼ í™œì„±í™”í•˜ì„¸ìš”.")
            
            if single_az_rds:
                recommendations.append(f"**RDS ê³ ê°€ìš©ì„±**: {len(single_az_rds)}ê°œì˜ Single-AZ RDS ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” Multi-AZ ë°°í¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # ê¸°ë³¸ ê¶Œì¥ì‚¬í•­
        if not recommendations:
            recommendations = [
                "**ë°±ì—… ì •ì±… ê²€í† **: ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°±ì—… ë³´ì¡´ ê¸°ê°„ê³¼ ë°±ì—… ìœˆë„ìš°ë¥¼ ê²€í† í•˜ì„¸ìš”.",
                "**ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: CloudWatchë¥¼ í†µí•´ ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ì§€í‘œë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”."
            ]
        
        for i, rec in enumerate(recommendations, 1):
            report_file.write(f"{i}. {rec}\n")
        
        report_file.write("\n### ğŸŸ¡ ì¤‘ê°„ ìš°ì„ ìˆœìœ„\n")
        report_file.write("1. **ì½ê¸° ì „ìš© ë³µì œë³¸**: ì½ê¸° ì›Œí¬ë¡œë“œ ë¶„ì‚°ì„ ìœ„í•œ ì½ê¸° ì „ìš© ë³µì œë³¸ êµ¬ì„±ì„ ê³ ë ¤í•˜ì„¸ìš”.\n")
        report_file.write("2. **íŒŒë¼ë¯¸í„° ê·¸ë£¹ ìµœì í™”**: ì›Œí¬ë¡œë“œì— ë§ëŠ” ë°ì´í„°ë² ì´ìŠ¤ íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìˆ˜í–‰í•˜ì„¸ìš”.\n")
        report_file.write("3. **ìë™ ë°±ì—… ì„¤ì •**: ìë™ ë°±ì—…ê³¼ í¬ì¸íŠ¸ ì¸ íƒ€ì„ ë³µêµ¬ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.\n\n")
        
        report_file.write("### ğŸŸ¢ ë‚®ì€ ìš°ì„ ìˆœìœ„\n")
        report_file.write("1. **ì„±ëŠ¥ ì¸ì‚¬ì´íŠ¸**: RDS Performance Insightsë¥¼ í™œì„±í™”í•˜ì—¬ ì„±ëŠ¥ ë¶„ì„ì„ ê°œì„ í•˜ì„¸ìš”.\n")
        report_file.write("2. **ë°ì´í„°ë² ì´ìŠ¤ í”„ë¡ì‹œ**: ì—°ê²° í’€ë§ì„ ìœ„í•œ RDS Proxy ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”.\n")
        report_file.write("3. **í¬ë¡œìŠ¤ ë¦¬ì „ ë³µì œ**: ì¬í•´ ë³µêµ¬ë¥¼ ìœ„í•œ í¬ë¡œìŠ¤ ë¦¬ì „ ë³µì œë¥¼ ê²€í† í•˜ì„¸ìš”.\n\n")

    def generate_report(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        print("ğŸ—„ï¸ Database Analysis ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        # ë°ì´í„° íŒŒì¼ ë¡œë“œ
        rds_data = self.load_json_file("database_rds_instances.json")
        dynamodb_data = self.load_json_file("database_dynamodb_tables.json")
        elasticache_data = self.load_json_file("database_elasticache_clusters.json")
        
        # ë³´ê³ ì„œ íŒŒì¼ ìƒì„±
        report_path = self.report_dir / "05-database-analysis.md"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as report_file:
                # í—¤ë” ì‘ì„±
                report_file.write("# ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„\n\n")
                
                # ê° ì„¹ì…˜ ì‘ì„±
                self.write_rds_analysis(report_file, rds_data)
                self.write_dynamodb_analysis(report_file, dynamodb_data)
                self.write_elasticache_analysis(report_file, elasticache_data)
                self.write_database_recommendations(report_file, rds_data, dynamodb_data)
                
                # ë§ˆë¬´ë¦¬
                report_file.write("---\n")
                report_file.write("*ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì™„ë£Œ*\n")
            
            print("âœ… Database Analysis ìƒì„± ì™„ë£Œ: 05-database-analysis.md")
            
        except IOError as e:
            print(f"âŒ ë³´ê³ ì„œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            sys.exit(1)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±")
    parser.add_argument("--report-dir", default="/home/ec2-user/amazonqcli_lab/aws-arch-analysis/report", help="ë³´ê³ ì„œ ë””ë ‰í† ë¦¬")
    
    args = parser.parse_args()
    
    generator = DatabaseReportGenerator(args.report_dir)
    generator.generate_report()

if __name__ == "__main__":
    main()
