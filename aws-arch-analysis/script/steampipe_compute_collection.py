#!/usr/bin/env python3
"""
ì™„ì „í•œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ (Kubernetes í¬í•¨)
Shell ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ê¸°ëŠ¥ ë° ì¶œë ¥ í˜•ì‹ ì œê³µ
"""

import subprocess
import json
import os
import sys
from pathlib import Path
from typing import List, Tuple
from datetime import datetime

class SteampipeComputeCollector:
    def __init__(self, region: str = "ap-northeast-2", report_dir: str = "/home/ec2-user/amazonqcli_lab/aws-arch-analysis/report"):
        self.region = region
        self.report_dir = Path(report_dir)
        self.report_dir.mkdir(parents=True, exist_ok=True)
        
        self.log_file = self.report_dir / "steampipe_compute_collection.log"
        self.error_log = self.report_dir / "steampipe_compute_errors.log"
        
        # ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™”
        self.log_file.write_text("")
        self.error_log.write_text("")
        
        self.total_count = 0
        self.success_count = 0
        
        # ìƒ‰ìƒ ì½”ë“œ
        self.RED = '\033[0;31m'
        self.GREEN = '\033[0;32m'
        self.YELLOW = '\033[1;33m'
        self.BLUE = '\033[0;34m'
        self.PURPLE = '\033[0;35m'
        self.CYAN = '\033[0;36m'
        self.NC = '\033[0m'  # No Color
        
    def log_info(self, message: str):
        print(f"{self.BLUE}[INFO]{self.NC} {message}")
        with open(self.log_file, 'a') as f:
            f.write(f"[INFO] {message}\n")
        
    def log_success(self, message: str):
        print(f"{self.GREEN}[SUCCESS]{self.NC} {message}")
        with open(self.log_file, 'a') as f:
            f.write(f"[SUCCESS] {message}\n")
        
    def log_warning(self, message: str):
        print(f"{self.YELLOW}[WARNING]{self.NC} {message}")
        with open(self.log_file, 'a') as f:
            f.write(f"[WARNING] {message}\n")
        
    def log_error(self, message: str):
        print(f"{self.RED}[ERROR]{self.NC} {message}")
        with open(self.error_log, 'a') as f:
            f.write(f"[ERROR] {message}\n")
            
    def log_container(self, message: str):
        print(f"{self.PURPLE}[CONTAINER]{self.NC} {message}")
        with open(self.log_file, 'a') as f:
            f.write(f"[CONTAINER] {message}\n")
            
    def log_k8s(self, message: str):
        print(f"{self.CYAN}[K8S]{self.NC} {message}")
        with open(self.log_file, 'a') as f:
            f.write(f"[K8S] {message}\n")

    def check_steampipe_plugin(self):
        """Steampipe AWS ë° Kubernetes í”ŒëŸ¬ê·¸ì¸ í™•ì¸"""
        self.log_info("Steampipe AWS í”ŒëŸ¬ê·¸ì¸ í™•ì¸ ì¤‘...")
        try:
            result = subprocess.run(
                ["steampipe", "plugin", "list"],
                capture_output=True,
                text=True,
                check=True
            )
            if "aws" not in result.stdout:
                self.log_warning("AWS í”ŒëŸ¬ê·¸ì¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘...")
                subprocess.run(["steampipe", "plugin", "install", "aws"], check=True)
        except subprocess.CalledProcessError:
            self.log_warning("Steampipe í”ŒëŸ¬ê·¸ì¸ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            
        # Kubernetes í”ŒëŸ¬ê·¸ì¸ í™•ì¸
        self.log_k8s("Steampipe Kubernetes í”ŒëŸ¬ê·¸ì¸ í™•ì¸ ì¤‘...")
        try:
            result = subprocess.run(
                ["steampipe", "plugin", "list"],
                capture_output=True,
                text=True,
                check=True
            )
            if "kubernetes" not in result.stdout:
                self.log_warning("Kubernetes í”ŒëŸ¬ê·¸ì¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘...")
                subprocess.run(["steampipe", "plugin", "install", "kubernetes"], check=True)
        except subprocess.CalledProcessError:
            self.log_warning("Kubernetes í”ŒëŸ¬ê·¸ì¸ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    def check_container_services(self):
        """ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ ì¡´ì¬ í™•ì¸"""
        self.log_container("ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ ì¡´ì¬ í™•ì¸ ì¤‘...")
        
        try:
            # ECS í´ëŸ¬ìŠ¤í„° ì¡´ì¬ í™•ì¸
            ecs_result = subprocess.run(
                ["aws", "ecs", "list-clusters", "--region", self.region, "--query", "clusterArns | length(@)", "--output", "text"],
                capture_output=True,
                text=True
            )
            ecs_clusters = int(ecs_result.stdout.strip()) if ecs_result.returncode == 0 else 0
            self.log_info(f"ECS í´ëŸ¬ìŠ¤í„° ê°œìˆ˜: {ecs_clusters}")
            
            # EKS í´ëŸ¬ìŠ¤í„° ì¡´ì¬ í™•ì¸
            eks_result = subprocess.run(
                ["aws", "eks", "list-clusters", "--region", self.region, "--query", "clusters | length(@)", "--output", "text"],
                capture_output=True,
                text=True
            )
            eks_clusters = int(eks_result.stdout.strip()) if eks_result.returncode == 0 else 0
            self.log_info(f"EKS í´ëŸ¬ìŠ¤í„° ê°œìˆ˜: {eks_clusters}")
            
            # ECR ë¦¬í¬ì§€í† ë¦¬ ì¡´ì¬ í™•ì¸
            ecr_result = subprocess.run(
                ["aws", "ecr", "describe-repositories", "--region", self.region, "--query", "repositories | length(@)", "--output", "text"],
                capture_output=True,
                text=True
            )
            ecr_repos = int(ecr_result.stdout.strip()) if ecr_result.returncode == 0 else 0
            self.log_info(f"ECR ë¦¬í¬ì§€í† ë¦¬ ê°œìˆ˜: {ecr_repos}")
            
            if ecs_clusters == 0 and eks_clusters == 0 and ecr_repos == 0:
                self.log_warning("ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘ì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            
            # Kubernetes ì—°ê²° í™•ì¸
            if eks_clusters > 0:
                self.log_k8s("EKS í´ëŸ¬ìŠ¤í„°ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. Kubernetes ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            self.log_warning(f"ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def execute_steampipe_query(self, description: str, query: str, output_file: str) -> bool:
        self.log_info(f"ìˆ˜ì§‘ ì¤‘: {description}")
        self.total_count += 1
        
        try:
            # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ report_dirë¡œ ë³€ê²½
            os.chdir(self.report_dir)
            
            result = subprocess.run(
                ["steampipe", "query", query, "--output", "json"],
                capture_output=True,
                text=True,
                check=True
            )
            
            output_path = self.report_dir / output_file
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(result.stdout)
            
            file_size = output_path.stat().st_size
            if file_size > 50:
                self.log_success(f"{description} ì™„ë£Œ ({output_file}, {file_size} bytes)")
                self.success_count += 1
                return True
            else:
                self.log_warning(f"{description} - ë°ì´í„° ì—†ìŒ ({output_file}, {file_size} bytes)")
                return False
                
        except subprocess.CalledProcessError as e:
            # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ error_logì— ê¸°ë¡
            error_msg = f"{description} ì‹¤íŒ¨ - {output_file}"
            if e.stderr:
                error_msg += f": {e.stderr.strip()}"
            self.log_error(error_msg)
            
            # ì˜¤ë¥˜ ë¡œê·¸ì— ì¶”ê°€ ì •ë³´ ê¸°ë¡
            with open(self.error_log, 'a') as f:
                f.write(f"\nQuery failed: {query}\n")
                f.write(f"Error: {e.stderr}\n")
            
            return False

    def get_ec2_queries(self) -> List[Tuple[str, str, str]]:
        """EC2 ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì¿¼ë¦¬"""
        return [
            (
                "EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„¸ ì •ë³´",
                f"select instance_id, instance_type, instance_state, vpc_id, subnet_id, private_ip_address, public_ip_address, private_dns_name, public_dns_name, key_name, security_groups, iam_instance_profile_arn, monitoring_state, placement_availability_zone, platform, architecture, virtualization_type, hypervisor, root_device_type, root_device_name, block_device_mappings, ebs_optimized, ena_support, sriov_net_support, source_dest_check, launch_time, state_transition_reason, usage_operation, usage_operation_update_time, tags from aws_ec2_instance where region = '{self.region}'",
                "compute_ec2_instances.json"
            ),
            (
                "EC2 AMI ì´ë¯¸ì§€",
                f"select image_id, name, description, state, public, owner_id, architecture, platform, virtualization_type, hypervisor, root_device_type, root_device_name, block_device_mappings, creation_date, deprecation_time, usage_operation, platform_details, image_type, image_location, kernel_id, ramdisk_id, sriov_net_support, ena_support, boot_mode, tags from aws_ec2_ami where region = '{self.region}' and owner_id = (select account_id from aws_caller_identity)",
                "compute_ec2_amis.json"
            ),
            (
                "EC2 í‚¤ í˜ì–´",
                f"select key_name, key_fingerprint, key_type, key_pair_id, create_time, tags from aws_ec2_key_pair where region = '{self.region}'",
                "compute_ec2_key_pairs.json"
            ),
            (
                "EC2 ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…",
                f"select instance_type, current_generation, free_tier_eligible, supported_usage_classes, supported_root_device_types, supported_virtualization_types, bare_metal, hypervisor, processor_info, vcpu_info, memory_info, instance_storage_info, ebs_info, network_info, gpu_info, fpga_info, placement_group_info, hibernation_supported, burstable_performance_supported, dedicated_hosts_supported, auto_recovery_supported, supported_boot_modes from aws_ec2_instance_type where region = '{self.region}'",
                "compute_ec2_instance_types.json"
            ),
            (
                "EC2 ìŠ¤íŒŸ ê°€ê²©",
                f"select instance_type, product_description, spot_price, timestamp, availability_zone from aws_ec2_spot_price where region = '{self.region}' and timestamp >= now() - interval '1 day'",
                "compute_ec2_spot_prices.json"
            ),
            (
                "EC2 ì˜ˆì•½ ì¸ìŠ¤í„´ìŠ¤",
                f"select reserved_instance_id, instance_type, availability_zone, instance_count, product_description, instance_state, start_time, end_time, duration, usage_price, fixed_price, currency_code, instance_tenancy, offering_class, offering_type, scope, tags from aws_ec2_reserved_instance where region = '{self.region}'",
                "compute_ec2_reserved_instances.json"
            ),
            (
                "EC2 ë°°ì¹˜ ê·¸ë£¹",
                f"select group_name, group_id, strategy, partition_count, state, tags from aws_ec2_placement_group where region = '{self.region}'",
                "compute_ec2_placement_groups.json"
            )
        ]

    def get_autoscaling_queries(self) -> List[Tuple[str, str, str]]:
        """Auto Scaling ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì¿¼ë¦¬"""
        return [
            (
                "Auto Scaling ê·¸ë£¹ ìƒì„¸ ì •ë³´",
                f"select name, autoscaling_group_arn, min_size, max_size, desired_capacity, default_cooldown, availability_zones, load_balancer_names, target_group_arns, health_check_type, health_check_grace_period, placement_group, vpc_zone_identifier, termination_policies, new_instances_protected_from_scale_in, service_linked_role_arn, max_instance_lifetime, capacity_rebalance, warm_pool_configuration, warm_pool_size, status, suspended_processes, enabled_metrics, tags from aws_ec2_autoscaling_group where region = '{self.region}'",
                "compute_asg_detailed.json"
            ),
            (
                "Auto Scaling ì‹œì‘ êµ¬ì„±",
                f"select launch_configuration_name, launch_configuration_arn, image_id, instance_type, key_name, security_groups, classic_link_vpc_id, classic_link_vpc_security_groups, user_data, instance_monitoring, spot_price, iam_instance_profile, created_time, ebs_optimized, associate_public_ip_address, placement_tenancy, block_device_mappings, metadata_options from aws_ec2_autoscaling_launch_configuration where region = '{self.region}'",
                "compute_asg_launch_configs.json"
            ),
            (
                "EC2 ì‹œì‘ í…œí”Œë¦¿",
                f"select launch_template_id, launch_template_name, create_time, created_by, default_version_number, latest_version_number, tags from aws_ec2_launch_template where region = '{self.region}'",
                "compute_ec2_launch_templates.json"
            ),
            (
                "EC2 ì‹œì‘ í…œí”Œë¦¿ ë²„ì „",
                f"select launch_template_id, launch_template_name, version_number, version_description, create_time, created_by, default_version, launch_template_data from aws_ec2_launch_template_version where region = '{self.region}'",
                "compute_ec2_launch_template_versions.json"
            )
        ]

    def get_loadbalancer_queries(self) -> List[Tuple[str, str, str]]:
        """ë¡œë“œ ë°¸ëŸ°ì‹± ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì¿¼ë¦¬"""
        return [
            (
                "Application Load Balancer ìƒì„¸ ì •ë³´",
                f"select arn, name, type, scheme, vpc_id, availability_zones, security_groups, ip_address_type, state_code, state_reason, dns_name, canonical_hosted_zone_id, created_time, load_balancer_attributes, tags from aws_ec2_application_load_balancer where region = '{self.region}'",
                "compute_alb_detailed.json"
            ),
            (
                "Network Load Balancer ìƒì„¸ ì •ë³´",
                f"select arn, name, type, scheme, vpc_id, availability_zones, ip_address_type, state_code, state_reason, dns_name, canonical_hosted_zone_id, created_time, load_balancer_attributes, tags from aws_ec2_network_load_balancer where region = '{self.region}'",
                "compute_nlb_detailed.json"
            ),
            (
                "Classic Load Balancer",
                f"select name, dns_name, canonical_hosted_zone_name, canonical_hosted_zone_name_id, vpc_id, subnets, security_groups, instances, availability_zones, backend_server_descriptions, connection_draining, cross_zone_load_balancing, access_log, connection_settings, created_time, scheme, source_security_group, tags from aws_ec2_classic_load_balancer where region = '{self.region}'",
                "compute_clb.json"
            ),
            (
                "íƒ€ê²Ÿ ê·¸ë£¹",
                f"select target_group_arn, target_group_name, protocol, port, vpc_id, health_check_enabled, health_check_interval_seconds, health_check_path, health_check_port, health_check_protocol, health_check_timeout_seconds, healthy_threshold_count, unhealthy_threshold_count, load_balancer_arns, target_type, protocol_version, ip_address_type, tags from aws_ec2_target_group where region = '{self.region}'",
                "compute_target_groups.json"
            ),
            (
                "ë¡œë“œ ë°¸ëŸ°ì„œ ë¦¬ìŠ¤ë„ˆ",
                f"select arn, load_balancer_arn, port, protocol, certificates, ssl_policy, default_actions from aws_ec2_load_balancer_listener where region = '{self.region}'",
                "compute_lb_listeners.json"
            ),
            (
                "ë¡œë“œ ë°¸ëŸ°ì„œ ë¦¬ìŠ¤ë„ˆ ê·œì¹™",
                f"select arn, listener_arn, priority, conditions, actions, is_default from aws_ec2_load_balancer_listener_rule where region = '{self.region}'",
                "compute_lb_listener_rules.json"
            )
        ]

    def get_serverless_queries(self) -> List[Tuple[str, str, str]]:
        """ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ… ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì¿¼ë¦¬"""
        return [
            (
                "Lambda í•¨ìˆ˜ ìƒì„¸ ì •ë³´",
                f"select name, arn, runtime, role, handler, code_size, description, timeout, memory_size, last_modified, code_sha_256, version, vpc_id, environment_variables, dead_letter_config_target_arn, kms_key_arn, tracing_config, master_arn, revision_id, layers, state, state_reason, state_reason_code, last_update_status, last_update_status_reason, last_update_status_reason_code, file_system_configs, package_type, architectures, ephemeral_storage, snap_start, logging_config, tags from aws_lambda_function where region = '{self.region}'",
                "compute_lambda_functions.json"
            ),
            (
                "Lambda ë ˆì´ì–´",
                f"select layer_name, layer_arn, version, description, created_date, compatible_runtimes, license_info, compatible_architectures from aws_lambda_layer_version where region = '{self.region}'",
                "compute_lambda_layers.json"
            ),
            (
                "Lambda ë³„ì¹­",
                f"select name, alias_arn, function_name, function_version, description, revision_id from aws_lambda_alias where region = '{self.region}'",
                "compute_lambda_aliases.json"
            ),
            (
                "Lambda ë²„ì „",
                f"select version, function_name, function_arn, description, code_size, code_sha_256, last_modified, master_arn, revision_id, layers, state, state_reason, state_reason_code, last_update_status, last_update_status_reason, last_update_status_reason_code from aws_lambda_version where region = '{self.region}'",
                "compute_lambda_versions.json"
            ),
            (
                "Lambda ì´ë²¤íŠ¸ ì†ŒìŠ¤ ë§¤í•‘",
                f"select uuid, arn, function_arn, function_name, last_modified, last_processing_result, state, state_transition_reason, batch_size, maximum_batching_window_in_seconds, parallelization_factor, starting_position, starting_position_timestamp, maximum_record_age_in_seconds, bisect_batch_on_function_error, maximum_retry_attempts, tumbling_window_in_seconds, topics, queues, source_access_configurations, self_managed_event_source, function_response_types, amazon_managed_kafka_event_source_config, self_managed_kafka_event_source_config, scaling_config from aws_lambda_event_source_mapping where region = '{self.region}'",
                "compute_lambda_event_mappings.json"
            )
        ]

    def get_container_queries(self) -> List[Tuple[str, str, str]]:
        """ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì¿¼ë¦¬"""
        return [
            (
                "ECS í´ëŸ¬ìŠ¤í„°",
                f"select cluster_name, cluster_arn, status, running_tasks_count, pending_tasks_count, active_services_count, statistics, tags, settings, configuration, service_connect_defaults, capacity_providers, default_capacity_provider_strategy from aws_ecs_cluster where region = '{self.region}'",
                "compute_ecs_clusters.json"
            ),
            (
                "ECS ì„œë¹„ìŠ¤",
                f"select service_name, service_arn, cluster_arn, task_definition, desired_count, running_count, pending_count, status, task_sets, deployment_controller, deployments, role_arn, events, created_at, platform_version, platform_family, tags, propagate_tags, enable_ecs_managed_tags, created_by, enable_execute_command, health_check_grace_period_seconds, scheduling_strategy, deployment_configuration, network_configuration, service_registries, scale_in_protection, capacity_provider_strategy from aws_ecs_service where region = '{self.region}'",
                "compute_ecs_services.json"
            ),
            (
                "ECS íƒœìŠ¤í¬",
                f"select task_arn, cluster_arn, task_definition_arn, container_instance_arn, overrides, last_status, desired_status, cpu, memory, containers, started_by, version, stopped_reason, stopped_at, connectivity, connectivity_at, pull_started_at, pull_stopped_at, execution_stopped_at, created_at, started_at, stopping_at, platform_version, platform_family, attributes, health_status, tags, group_name, launch_type, capacity_provider_name, availability_zone, ephemeral_storage from aws_ecs_task where region = '{self.region}'",
                "compute_ecs_tasks.json"
            ),
            (
                "ECS íƒœìŠ¤í¬ ì •ì˜",
                f"select task_definition_arn, family, task_role_arn, execution_role_arn, network_mode, revision, volumes, status, requires_attributes, placement_constraints, compatibilities, runtime_platform, requires_compatibilities, cpu, memory, inference_accelerators, pid_mode, ipc_mode, proxy_configuration, registered_at, deregistered_at, registered_by, ephemeral_storage from aws_ecs_task_definition where region = '{self.region}'",
                "compute_ecs_task_definitions.json"
            ),
            (
                "ECS ì»¨í…Œì´ë„ˆ ì¸ìŠ¤í„´ìŠ¤",
                f"select container_instance_arn, ec2_instance_id, capacity_provider_name, version, version_info, remaining_resources, registered_resources, status, status_reason, agent_connected, running_tasks_count, pending_tasks_count, agent_update_status, attributes, registered_at, attachments, tags from aws_ecs_container_instance where region = '{self.region}'",
                "compute_ecs_container_instances.json"
            ),
            (
                "EKS í´ëŸ¬ìŠ¤í„°",
                f"select name, arn, created_at, version, endpoint, role_arn, resources_vpc_config, kubernetes_network_config, logging, identity, status, certificate_authority, client_request_token, platform_version, tags, encryption_config, connector_config, id, health, outpost_config, access_config from aws_eks_cluster where region = '{self.region}'",
                "compute_eks_clusters.json"
            ),
            (
                "EKS ë…¸ë“œ ê·¸ë£¹",
                f"select cluster_name, nodegroup_name, nodegroup_arn, status, capacity_type, scaling_config, instance_types, subnets, remote_access, ami_type, node_role, labels, taints, resources, health, update_config, launch_template, version, release_version, created_at, modified_at, tags from aws_eks_node_group where region = '{self.region}'",
                "compute_eks_node_groups.json"
            ),
            (
                "EKS Fargate í”„ë¡œí•„",
                f"select fargate_profile_name, fargate_profile_arn, cluster_name, created_at, pod_execution_role_arn, subnets, selectors, status, tags from aws_eks_fargate_profile where region = '{self.region}'",
                "compute_eks_fargate_profiles.json"
            ),
            (
                "EKS ì• ë“œì˜¨",
                f"select addon_name, cluster_name, addon_arn, addon_version, status, health, configuration_values, resolve_conflicts, service_account_role_arn, created_at, modified_at, tags from aws_eks_addon where region = '{self.region}'",
                "compute_eks_addons.json"
            ),
            (
                "EKS ì•„ì´ë´í‹°í‹° ì œê³µì",
                f"select cluster_name, identity_provider_config_name, identity_provider_config_arn, type, status, tags from aws_eks_identity_provider_config where region = '{self.region}'",
                "compute_eks_identity_providers.json"
            ),
            (
                "Fargate íƒœìŠ¤í¬",
                f"select task_arn, cluster_arn, task_definition_arn, overrides, last_status, desired_status, cpu, memory, containers, started_by, version, stopped_reason, stopped_at, connectivity, connectivity_at, pull_started_at, pull_stopped_at, execution_stopped_at, created_at, started_at, stopping_at, platform_version, platform_family, attributes, health_status, tags, group_name, launch_type, capacity_provider_name, availability_zone, ephemeral_storage from aws_ecs_task where region = '{self.region}' and launch_type = 'FARGATE'",
                "compute_fargate_tasks.json"
            )
        ]

    def get_k8s_queries(self) -> List[Tuple[str, str, str]]:
        """Kubernetes ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì¿¼ë¦¬"""
        return [
            (
                "K8s ë„¤ì„ìŠ¤í˜ì´ìŠ¤",
                "select name, uid, creation_timestamp, deletion_timestamp, labels, annotations from kubernetes_namespace",
                "k8s_namespaces.json"
            ),
            (
                "K8s íŒŒë“œ",
                "select name, namespace, uid, node_name, phase, pod_ip, host_ip, qos_class, restart_policy, service_account_name, node_selector, tolerations, affinity, priority, priority_class_name, runtime_class_name, overhead, topology_spread_constraints, preemption_policy, os, host_network, host_pid, host_ipc, share_process_namespace, security_context, dns_policy, dns_config, hostname, subdomain, scheduler_name, creation_timestamp, deletion_timestamp, labels, annotations from kubernetes_pod",
                "k8s_pods.json"
            ),
            (
                "K8s ë””í”Œë¡œì´ë¨¼íŠ¸",
                "select name, namespace, uid, replicas, updated_replicas, ready_replicas, available_replicas, unavailable_replicas, observed_generation, creation_timestamp, labels, annotations from kubernetes_deployment",
                "k8s_deployments.json"
            ),
            (
                "K8s ì„œë¹„ìŠ¤",
                "select name, namespace, uid, type, cluster_ip, cluster_ips, external_ips, session_affinity, external_name, external_traffic_policy, health_check_node_port, publish_not_ready_addresses, ip_families, ip_family_policy, allocate_load_balancer_node_ports, load_balancer_class, internal_traffic_policy, creation_timestamp, labels, annotations from kubernetes_service",
                "k8s_services.json"
            ),
            (
                "K8s ë…¸ë“œ",
                "select name, uid, pod_cidr, pod_cidrs, provider_id, unschedulable, creation_timestamp, labels, annotations from kubernetes_node",
                "k8s_nodes.json"
            ),
            (
                "K8s ì¸ê·¸ë ˆìŠ¤",
                "select name, namespace, uid, ingress_class_name, creation_timestamp, labels, annotations from kubernetes_ingress",
                "k8s_ingress.json"
            ),
            (
                "K8s ì»¨í”¼ê·¸ë§µ",
                "select name, namespace, uid, data, binary_data, immutable, creation_timestamp, labels, annotations from kubernetes_config_map",
                "k8s_configmaps.json"
            ),
            (
                "K8s ì‹œí¬ë¦¿",
                "select name, namespace, uid, type, data, string_data, immutable, creation_timestamp, labels, annotations from kubernetes_secret",
                "k8s_secrets.json"
            ),
            (
                "K8s í¼ì‹œìŠ¤í„´íŠ¸ ë³¼ë¥¨",
                "select name, uid, capacity, access_modes, reclaim_policy, storage_class, mount_options, volume_mode, node_affinity, creation_timestamp, labels, annotations from kubernetes_persistent_volume",
                "k8s_persistent_volumes.json"
            ),
            (
                "K8s í¼ì‹œìŠ¤í„´íŠ¸ ë³¼ë¥¨ í´ë ˆì„",
                "select name, namespace, uid, access_modes, storage_class, volume_name, volume_mode, creation_timestamp, labels, annotations from kubernetes_persistent_volume_claim",
                "k8s_persistent_volume_claims.json"
            ),
            (
                "K8s ë°ëª¬ì…‹",
                "select name, namespace, uid, current_number_scheduled, desired_number_scheduled, number_available, number_misscheduled, number_ready, number_unavailable, updated_number_scheduled, observed_generation, creation_timestamp, labels, annotations from kubernetes_daemonset",
                "k8s_daemonsets.json"
            ),
            (
                "K8s ìŠ¤í…Œì´íŠ¸í’€ì…‹",
                "select name, namespace, uid, replicas, ready_replicas, current_replicas, updated_replicas, current_revision, update_revision, observed_generation, collision_count, creation_timestamp, labels, annotations from kubernetes_stateful_set",
                "k8s_statefulsets.json"
            ),
            (
                "K8s ì¡",
                "select name, namespace, uid, parallelism, completions, active_deadline_seconds, backoff_limit, selector, manual_selector, completion_mode, suspend, creation_timestamp, labels, annotations from kubernetes_job",
                "k8s_jobs.json"
            ),
            (
                "K8s í¬ë¡ ì¡",
                "select name, namespace, uid, schedule, timezone, starting_deadline_seconds, concurrency_policy, suspend, successful_jobs_history_limit, failed_jobs_history_limit, creation_timestamp, labels, annotations from kubernetes_cronjob",
                "k8s_cronjobs.json"
            )
        ]

    def get_other_queries(self) -> List[Tuple[str, str, str]]:
        """ê¸°íƒ€ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì¿¼ë¦¬"""
        return [
            (
                "Elastic Beanstalk ì• í”Œë¦¬ì¼€ì´ì…˜",
                f"select name, description, date_created, date_updated, versions, configuration_templates, resource_lifecycle_config from aws_elastic_beanstalk_application where region = '{self.region}'",
                "compute_beanstalk_applications.json"
            ),
            (
                "Elastic Beanstalk í™˜ê²½",
                f"select environment_name, environment_id, application_name, version_label, solution_stack_name, platform_arn, template_name, description, endpoint_url, cname, date_created, date_updated, status, abortable_operation_in_progress, health, health_status, resources, tier, environment_links, environment_arn, operations_role from aws_elastic_beanstalk_environment where region = '{self.region}'",
                "compute_beanstalk_environments.json"
            ),
            (
                "Batch ì‘ì—… í",
                f"select job_queue_name, job_queue_arn, state, status, status_reason, priority, compute_environment_order, tags from aws_batch_job_queue where region = '{self.region}'",
                "compute_batch_queues.json"
            ),
            (
                "Batch ì»´í“¨íŒ… í™˜ê²½",
                f"select compute_environment_name, compute_environment_arn, arn, type, state, status, status_reason, compute_resources, service_role, tags from aws_batch_compute_environment where region = '{self.region}'",
                "compute_batch_environments.json"
            ),
            (
                "Lightsail ì¸ìŠ¤í„´ìŠ¤",
                f"select name, arn, support_code, created_at, location, resource_type, tags, blueprint_id, blueprint_name, bundle_id, add_ons, is_static_ip, private_ip_address, public_ip_address, ipv6_addresses, hardware, networking, state, username, ssh_key_name from aws_lightsail_instance where region = '{self.region}'",
                "compute_lightsail_instances.json"
            )
        ]

    def collect_data(self):
        """ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰"""
        self.log_container("ğŸš€ ì™„ì „í•œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (Kubernetes í¬í•¨)")
        self.log_info(f"Region: {self.region}")
        self.log_info(f"Report Directory: {self.report_dir}")
        
        # Steampipe í”ŒëŸ¬ê·¸ì¸ í™•ì¸
        self.check_steampipe_plugin()
        
        # ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ í™•ì¸
        self.check_container_services()
        
        # EC2 ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
        self.log_info("ğŸ’» EC2 ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        ec2_queries = self.get_ec2_queries()
        for description, query, output_file in ec2_queries:
            self.execute_steampipe_query(description, query, output_file)
        
        # Auto Scaling ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
        self.log_info("âš–ï¸ Auto Scaling ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        autoscaling_queries = self.get_autoscaling_queries()
        for description, query, output_file in autoscaling_queries:
            self.execute_steampipe_query(description, query, output_file)
        
        # ë¡œë“œ ë°¸ëŸ°ì‹± ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
        self.log_info("ğŸ”„ ë¡œë“œ ë°¸ëŸ°ì‹± ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        loadbalancer_queries = self.get_loadbalancer_queries()
        for description, query, output_file in loadbalancer_queries:
            self.execute_steampipe_query(description, query, output_file)
        
        # ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
        self.log_info("ğŸš€ ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        serverless_queries = self.get_serverless_queries()
        for description, query, output_file in serverless_queries:
            self.execute_steampipe_query(description, query, output_file)
        
        # ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
        self.log_container("ğŸ“¦ ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        container_queries = self.get_container_queries()
        for description, query, output_file in container_queries:
            self.execute_steampipe_query(description, query, output_file)
        
        # Kubernetes ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
        self.log_k8s("â˜¸ï¸ Kubernetes ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        k8s_queries = self.get_k8s_queries()
        for description, query, output_file in k8s_queries:
            if self.execute_steampipe_query(description, query, output_file):
                pass
            else:
                self.log_warning(f"Kubernetes ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {description} (í´ëŸ¬ìŠ¤í„° ì—°ê²° í™•ì¸ í•„ìš”)")
        
        # ê¸°íƒ€ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ ìˆ˜ì§‘
        self.log_info("ğŸ—ï¸ ê¸°íƒ€ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        other_queries = self.get_other_queries()
        for description, query, output_file in other_queries:
            self.execute_steampipe_query(description, query, output_file)
        
        # ê²°ê³¼ ìš”ì•½
        self.log_success("ì™„ì „í•œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        self.log_info(f"ì„±ê³µ: {self.success_count}/{self.total_count}")
        
        # íŒŒì¼ ëª©ë¡ ë° í¬ê¸° í‘œì‹œ
        self.display_file_list()
        self.display_statistics()
        self.display_error_summary()
        self.display_next_steps()
        
        self.log_container("ğŸ‰ ì™„ì „í•œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    def display_file_list(self):
        """ìƒì„±ëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ"""
        print(f"\n{self.BLUE}ğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡:{self.NC}")
        
        # ì»´í“¨íŒ… ë° K8s ê´€ë ¨ íŒŒì¼ë“¤ ê²€ìƒ‰
        patterns = ["compute_*.json", "k8s_*.json"]
        files_found = []
        
        for pattern in patterns:
            files_found.extend(self.report_dir.glob(pattern))
        
        files_found.sort()
        
        for file_path in files_found:
            file_size = file_path.stat().st_size
            if file_size > 100:
                print(f"{self.GREEN}âœ“ {file_path.name} ({file_size} bytes){self.NC}")
            else:
                print(f"{self.YELLOW}âš  {file_path.name} ({file_size} bytes) - ë°ì´í„° ì—†ìŒ{self.NC}")

    def display_statistics(self):
        """ìˆ˜ì§‘ í†µê³„ í‘œì‹œ"""
        print(f"\n{self.BLUE}ğŸ“Š ìˆ˜ì§‘ í†µê³„:{self.NC}")
        print(f"ì´ ì¿¼ë¦¬ ìˆ˜: {self.total_count}")
        print(f"ì„±ê³µí•œ ì¿¼ë¦¬: {self.success_count}")
        print(f"ì‹¤íŒ¨í•œ ì¿¼ë¦¬: {self.total_count - self.success_count}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ í˜„í™©
        print(f"\n{self.BLUE}ğŸ“‹ ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ í˜„í™©:{self.NC}")
        print("ğŸ’» EC2 ê´€ë ¨: 7ê°œ")
        print("âš–ï¸ Auto Scaling: 4ê°œ")
        print("ğŸ”„ ë¡œë“œ ë°¸ëŸ°ì‹±: 6ê°œ")
        print("ğŸš€ ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ…: 5ê°œ")
        print("ğŸ“¦ ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤: 11ê°œ")
        print("â˜¸ï¸ Kubernetes: 13ê°œ")
        print("ğŸ—ï¸ ê¸°íƒ€ ì»´í“¨íŒ…: 5ê°œ")
        print("ğŸ“Š ì´ ë¦¬ì†ŒìŠ¤ íƒ€ì…: 51ê°œ")

    def display_error_summary(self):
        """ì˜¤ë¥˜ ìš”ì•½ í‘œì‹œ"""
        if self.error_log.exists() and self.error_log.stat().st_size > 0:
            self.log_warning(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. {self.error_log.name} íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            print(f"\n{self.YELLOW}ìµœê·¼ ì˜¤ë¥˜ (ë§ˆì§€ë§‰ 5ì¤„):{self.NC}")
            try:
                with open(self.error_log, 'r') as f:
                    lines = f.readlines()
                    for line in lines[-5:]:
                        print(line.strip())
            except Exception:
                pass

    def display_next_steps(self):
        """ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´"""
        print(f"\n{self.YELLOW}ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:{self.NC}")
        print("1. ìˆ˜ì§‘ëœ ì™„ì „í•œ ì»´í“¨íŒ… ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸ ë¶„ì„ ì§„í–‰")
        print("2. EC2 ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ìµœì í™” ë° ë¹„ìš© ë¶„ì„")
        print("3. Auto Scaling ë° Load Balancer êµ¬ì„± ìµœì í™” ê²€í† ")
        print("4. Lambda í•¨ìˆ˜ ì„±ëŠ¥ ë° ë¹„ìš© ìµœì í™” ë¶„ì„")
        print("5. ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ (ECS/EKS) ë¦¬ì†ŒìŠ¤ í™œìš©ë„ ë¶„ì„")
        print("6. Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì„± ë° ì›Œí¬ë¡œë“œ ë¶„ì„")
        print("7. ì„œë²„ë¦¬ìŠ¤ vs ì»¨í…Œì´ë„ˆ vs EC2 ë¹„ìš© íš¨ìœ¨ì„± ë¹„êµ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ì™„ì „í•œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (Kubernetes í¬í•¨)")
    parser.add_argument("--region", default=os.getenv("AWS_REGION", "ap-northeast-2"), help="AWS ë¦¬ì „")
    parser.add_argument("--report-dir", default=os.getenv("REPORT_DIR", "/home/ec2-user/amazonqcli_lab/aws-arch-analysis/report"), help="ë³´ê³ ì„œ ë””ë ‰í† ë¦¬")
    
    args = parser.parse_args()
    
    collector = SteampipeComputeCollector(args.region, args.report_dir)
    collector.collect_data()

if __name__ == "__main__":
    main()
