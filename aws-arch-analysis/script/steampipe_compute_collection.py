#!/usr/bin/env python3
"""
AWS ì»´í“¨íŒ… ë° ì„œë²„ë¦¬ìŠ¤ ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
Shell ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ì¿¼ë¦¬ êµ¬ì¡° ì‚¬ìš©
"""

import subprocess
import json
import os
import sys
from pathlib import Path
from typing import List, Tuple
from datetime import datetime

class SteampipeComputeCollector:
    def __init__(self, region: str = "ap-northeast-2"):
        self.region = region
        self.report_dir = Path("/home/ec2-user/amazonqcli_lab/aws-arch-analysis/report")
        self.report_dir.mkdir(parents=True, exist_ok=True)
        self.total_count = 0
        self.success_count = 0
        self.error_log = self.report_dir / "compute_collection_errors.log"
        
        # ìƒ‰ìƒ ì½”ë“œ
        self.GREEN = '\033[0;32m'
        self.BLUE = '\033[0;34m'
        self.YELLOW = '\033[1;33m'
        self.RED = '\033[0;31m'
        self.NC = '\033[0m'  # No Color
        
    def log_info(self, message: str):
        print(f"{self.BLUE}â„¹ï¸ {message}{self.NC}")
        
    def log_success(self, message: str):
        print(f"{self.GREEN}âœ… {message}{self.NC}")
        
    def log_warning(self, message: str):
        print(f"{self.YELLOW}âš ï¸ {message}{self.NC}")
        
    def log_error(self, message: str):
        print(f"{self.RED}âŒ {message}{self.NC}")

    def check_steampipe_plugin(self):
        """Steampipe AWS í”ŒëŸ¬ê·¸ì¸ í™•ì¸"""
        self.log_info("Steampipe AWS í”ŒëŸ¬ê·¸ì¸ í™•ì¸ ì¤‘...")
        try:
            result = subprocess.run(
                ["steampipe", "plugin", "list"],
                capture_output=True,
                text=True,
                check=True
            )
            if "aws" not in result.stdout:
                self.log_warning("AWS í”ŒëŸ¬ê·¸ì¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘...")
                subprocess.run(["steampipe", "plugin", "install", "aws"], check=True)
        except subprocess.CalledProcessError:
            self.log_warning("Steampipe í”ŒëŸ¬ê·¸ì¸ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    def execute_steampipe_query(self, description: str, query: str, output_file: str) -> bool:
        self.log_info(f"ìˆ˜ì§‘ ì¤‘: {description}")
        self.total_count += 1
        
        try:
            # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ report_dirë¡œ ë³€ê²½
            os.chdir(self.report_dir)
            
            result = subprocess.run(
                ["steampipe", "query", query, "--output", "json"],
                capture_output=True,
                text=True,
                check=True
            )
            
            output_path = self.report_dir / output_file
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(result.stdout)
            
            file_size = output_path.stat().st_size
            if file_size > 100:
                self.log_success(f"{description} ì™„ë£Œ ({output_file}, {file_size} bytes)")
                self.success_count += 1
                return True
            else:
                self.log_warning(f"{description} - ë°ì´í„° ì—†ìŒ ({output_file}, {file_size} bytes)")
                return False
                
        except subprocess.CalledProcessError as e:
            # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ error_logì— ê¸°ë¡
            error_msg = f"{description} ì‹¤íŒ¨ - {output_file}"
            if e.stderr:
                error_msg += f": {e.stderr.strip()}"
            self.log_error(error_msg)
            
            # ì˜¤ë¥˜ ë¡œê·¸ì— ì¶”ê°€ ì •ë³´ ê¸°ë¡
            with open(self.error_log, 'a') as f:
                f.write(f"\nQuery failed: {query}\n")
                f.write(f"Error: {e.stderr}\n")
            
            return False

    def get_compute_queries(self) -> List[Tuple[str, str, str]]:
        """Shell ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ì¿¼ë¦¬ êµ¬ì¡° ì‚¬ìš©"""
        return [
            # EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„¸ ì •ë³´
            (
                "EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„¸ ì •ë³´",
                f"select instance_id, instance_type, instance_state, vpc_id, subnet_id, private_ip_address, public_ip_address, private_dns_name, public_dns_name, key_name, security_groups, iam_instance_profile_arn, monitoring_state, placement_availability_zone, platform, architecture, virtualization_type, hypervisor, root_device_type, root_device_name, block_device_mappings, ebs_optimized, ena_support, sriov_net_support, source_dest_check, launch_time, state_transition_reason, usage_operation, usage_operation_update_time, tags from aws_ec2_instance where region = '{self.region}'",
                "compute_ec2_instances.json"
            ),
            
            # EC2 AMI ì´ë¯¸ì§€
            (
                "EC2 AMI ì´ë¯¸ì§€",
                f"select image_id, name, description, state, public, owner_id, architecture, platform, virtualization_type, hypervisor, root_device_type, root_device_name, block_device_mappings, creation_date, deprecation_time, usage_operation, platform_details, image_type, image_location, kernel_id, ramdisk_id, sriov_net_support, ena_support, boot_mode, tags from aws_ec2_ami where region = '{self.region}' and owner_id = (select account_id from aws_caller_identity)",
                "compute_ec2_amis.json"
            ),
            
            # EC2 í‚¤ í˜ì–´
            (
                "EC2 í‚¤ í˜ì–´",
                f"select key_name, key_fingerprint, key_type, key_pair_id, create_time, tags from aws_ec2_key_pair where region = '{self.region}'",
                "compute_ec2_key_pairs.json"
            ),
            
            # EC2 ì˜ˆì•½ ì¸ìŠ¤í„´ìŠ¤
            (
                "EC2 ì˜ˆì•½ ì¸ìŠ¤í„´ìŠ¤",
                f"select reserved_instance_id, instance_type, availability_zone, instance_count, product_description, instance_state, start_time, end_time, duration, usage_price, fixed_price, currency_code, instance_tenancy, offering_class, offering_type, scope, tags from aws_ec2_reserved_instance where region = '{self.region}'",
                "compute_ec2_reserved_instances.json"
            ),
            
            # EC2 ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ ìš”ì²­
            (
                "EC2 ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ ìš”ì²­",
                f"select spot_instance_request_id, spot_price, type, state, status, fault, valid_from, valid_until, launch_group, availability_zone_group, launch_specification, instance_id, create_time, product_description, block_duration_minutes, actual_block_hourly_price, tags from aws_ec2_spot_instance_request where region = '{self.region}'",
                "compute_ec2_spot_requests.json"
            ),
            
            # EC2 ë°°ì¹˜ ê·¸ë£¹
            (
                "EC2 ë°°ì¹˜ ê·¸ë£¹",
                f"select group_name, group_id, strategy, partition_count, state, tags from aws_ec2_placement_group where region = '{self.region}'",
                "compute_ec2_placement_groups.json"
            ),
            
            # EC2 ì‹œì‘ í…œí”Œë¦¿
            (
                "EC2 ì‹œì‘ í…œí”Œë¦¿",
                f"select launch_template_id, launch_template_name, create_time, created_by, default_version_number, latest_version_number, tags from aws_ec2_launch_template where region = '{self.region}'",
                "compute_ec2_launch_templates.json"
            ),
            
            # EC2 ì‹œì‘ í…œí”Œë¦¿ ë²„ì „
            (
                "EC2 ì‹œì‘ í…œí”Œë¦¿ ë²„ì „",
                f"select launch_template_id, launch_template_name, version_number, version_description, create_time, created_by, default_version, launch_template_data from aws_ec2_launch_template_version where region = '{self.region}'",
                "compute_ec2_launch_template_versions.json"
            ),
            
            # Application Load Balancer
            (
                "Application Load Balancer ìƒì„¸ ì •ë³´",
                f"select arn, name, type, scheme, vpc_id, availability_zones, security_groups, ip_address_type, state_code, state_reason, dns_name, canonical_hosted_zone_id, created_time, load_balancer_attributes, tags from aws_ec2_application_load_balancer where region = '{self.region}'",
                "compute_alb_detailed.json"
            ),
            
            # Network Load Balancer
            (
                "Network Load Balancer ìƒì„¸ ì •ë³´",
                f"select arn, name, type, scheme, vpc_id, availability_zones, ip_address_type, state_code, state_reason, dns_name, canonical_hosted_zone_id, created_time, load_balancer_attributes, tags from aws_ec2_network_load_balancer where region = '{self.region}'",
                "compute_nlb_detailed.json"
            ),
            
            # Classic Load Balancer
            (
                "Classic Load Balancer",
                f"select name, dns_name, canonical_hosted_zone_name, canonical_hosted_zone_name_id, vpc_id, subnets, security_groups, instances, availability_zones, backend_server_descriptions, connection_draining, cross_zone_load_balancing, access_log, connection_settings, created_time, scheme, source_security_group, tags from aws_ec2_classic_load_balancer where region = '{self.region}'",
                "compute_clb.json"
            ),
            
            # íƒ€ê²Ÿ ê·¸ë£¹
            (
                "íƒ€ê²Ÿ ê·¸ë£¹",
                f"select target_group_arn, target_group_name, protocol, port, vpc_id, health_check_enabled, health_check_interval_seconds, health_check_path, health_check_port, health_check_protocol, health_check_timeout_seconds, healthy_threshold_count, unhealthy_threshold_count, load_balancer_arns, target_type, protocol_version, ip_address_type, tags from aws_ec2_target_group where region = '{self.region}'",
                "compute_target_groups.json"
            ),
            
            # Auto Scaling ê·¸ë£¹
            (
                "Auto Scaling ê·¸ë£¹ ìƒì„¸ ì •ë³´",
                f"select name, autoscaling_group_arn, min_size, max_size, desired_capacity, default_cooldown, availability_zones, load_balancer_names, target_group_arns, health_check_type, health_check_grace_period, placement_group, vpc_zone_identifier, termination_policies, new_instances_protected_from_scale_in, service_linked_role_arn, max_instance_lifetime, capacity_rebalance, warm_pool_configuration, warm_pool_size, status, suspended_processes, enabled_metrics, tags from aws_ec2_autoscaling_group where region = '{self.region}'",
                "compute_asg_detailed.json"
            ),
            
            # Auto Scaling ì‹œì‘ êµ¬ì„±
            (
                "Auto Scaling ì‹œì‘ êµ¬ì„±",
                f"select launch_configuration_name, launch_configuration_arn, image_id, instance_type, key_name, security_groups, classic_link_vpc_id, classic_link_vpc_security_groups, user_data, instance_monitoring, spot_price, iam_instance_profile, created_time, ebs_optimized, associate_public_ip_address, placement_tenancy, block_device_mappings, metadata_options from aws_ec2_autoscaling_launch_configuration where region = '{self.region}'",
                "compute_asg_launch_configs.json"
            ),
            
            # Auto Scaling ì •ì±…
            (
                "Auto Scaling ì •ì±…",
                f"select policy_name, policy_arn, auto_scaling_group_name, policy_type, adjustment_type, min_adjustment_step, min_adjustment_magnitude, scaling_adjustment, cooldown, step_adjustments, metric_aggregation_type, estimated_instance_warmup, target_tracking_configuration, enabled, alarms from aws_ec2_autoscaling_policy where region = '{self.region}'",
                "compute_asg_policies.json"
            ),
            
            # Elastic Beanstalk ì• í”Œë¦¬ì¼€ì´ì…˜
            (
                "Elastic Beanstalk ì• í”Œë¦¬ì¼€ì´ì…˜",
                f"select name, description, date_created, date_updated, versions, configuration_templates, resource_lifecycle_config from aws_elastic_beanstalk_application where region = '{self.region}'",
                "compute_beanstalk_applications.json"
            ),
            
            # Elastic Beanstalk í™˜ê²½
            (
                "Elastic Beanstalk í™˜ê²½",
                f"select environment_name, environment_id, application_name, version_label, solution_stack_name, platform_arn, template_name, description, endpoint_url, cname, date_created, date_updated, status, abortable_operation_in_progress, health, health_status, resources, tier, environment_links, environment_arn, operations_role from aws_elastic_beanstalk_environment where region = '{self.region}'",
                "compute_beanstalk_environments.json"
            ),
            
            # Lambda í•¨ìˆ˜
            (
                "Lambda í•¨ìˆ˜ ìƒì„¸ ì •ë³´",
                f"select name, arn, runtime, role, handler, code_size, description, timeout, memory_size, last_modified, code_sha_256, version, vpc_id, environment_variables, dead_letter_config_target_arn, kms_key_arn, tracing_config, master_arn, revision_id, layers, state, state_reason, state_reason_code, last_update_status, last_update_status_reason, last_update_status_reason_code, file_system_configs, package_type, architectures, ephemeral_storage, snap_start, logging_config, tags from aws_lambda_function where region = '{self.region}'",
                "compute_lambda_functions.json"
            ),
            
            # Lambda ë ˆì´ì–´
            (
                "Lambda ë ˆì´ì–´",
                f"select layer_name, layer_arn, version, description, created_date, compatible_runtimes, license_info, compatible_architectures from aws_lambda_layer_version where region = '{self.region}'",
                "compute_lambda_layers.json"
            ),
            
            # Lambda ë³„ì¹­
            (
                "Lambda ë³„ì¹­",
                f"select name, alias_arn, function_name, function_version, description, revision_id from aws_lambda_alias where region = '{self.region}'",
                "compute_lambda_aliases.json"
            ),
            
            # Lambda ì´ë²¤íŠ¸ ì†ŒìŠ¤ ë§¤í•‘
            (
                "Lambda ì´ë²¤íŠ¸ ì†ŒìŠ¤ ë§¤í•‘",
                f"select uuid, arn, function_arn, function_name, last_modified, last_processing_result, state, state_transition_reason, batch_size, maximum_batching_window_in_seconds, parallelization_factor, starting_position, starting_position_timestamp, maximum_record_age_in_seconds, bisect_batch_on_function_error, maximum_retry_attempts, tumbling_window_in_seconds, topics, queues, source_access_configurations, self_managed_event_source, function_response_types, amazon_managed_kafka_event_source_config, self_managed_kafka_event_source_config, scaling_config from aws_lambda_event_source_mapping where region = '{self.region}'",
                "compute_lambda_event_mappings.json"
            )
        ]

    def collect_data(self):
        """ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰"""
        self.log_info("ğŸš€ ì»´í“¨íŒ… ë° ì„œë²„ë¦¬ìŠ¤ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        
        # Steampipe í”ŒëŸ¬ê·¸ì¸ í™•ì¸
        self.check_steampipe_plugin()
        
        # ì¿¼ë¦¬ ì‹¤í–‰
        queries = self.get_compute_queries()
        for description, query, output_file in queries:
            self.execute_steampipe_query(description, query, output_file)
        
        # ê²°ê³¼ ìš”ì•½
        self.log_success("ì»´í“¨íŒ… ë° ì„œë²„ë¦¬ìŠ¤ ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        self.log_info(f"ì„±ê³µ: {self.success_count}/{self.total_count}")
        
        # íŒŒì¼ ëª©ë¡ ë° í¬ê¸° í‘œì‹œ
        print(f"\n{self.BLUE}ğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡:{self.NC}")
        for file_path in sorted(self.report_dir.glob("compute_*.json")):
            file_size = file_path.stat().st_size
            if file_size > 100:
                print(f"{self.GREEN}âœ“ {file_path.name} ({file_size} bytes){self.NC}")
            else:
                print(f"{self.YELLOW}âš  {file_path.name} ({file_size} bytes) - ë°ì´í„° ì—†ìŒ{self.NC}")
        
        # ìˆ˜ì§‘ í†µê³„
        print(f"\n{self.BLUE}ğŸ“Š ìˆ˜ì§‘ í†µê³„:{self.NC}")
        print(f"ì´ ì¿¼ë¦¬ ìˆ˜: {self.total_count}")
        print(f"ì„±ê³µí•œ ì¿¼ë¦¬: {self.success_count}")
        print(f"ì‹¤íŒ¨í•œ ì¿¼ë¦¬: {self.total_count - self.success_count}")
        print(f"ì„±ê³µë¥ : {(self.success_count/self.total_count*100):.1f}%")
        
        if self.error_log.exists():
            print(f"\n{self.YELLOW}âš ï¸ ì˜¤ë¥˜ ë¡œê·¸: {self.error_log}{self.NC}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    region = os.environ.get('AWS_DEFAULT_REGION', 'ap-northeast-2')
    collector = SteampipeComputeCollector(region)
    collector.collect_data()

if __name__ == "__main__":
    main()
