#!/bin/bash
# ì™„ì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ (RDS, NoSQL, ë¶„ì„ ì„œë¹„ìŠ¤ í¬í•¨)

# ì„¤ì • ë³€ìˆ˜
REGION="${AWS_REGION:-ap-northeast-2}"
REPORT_DIR="${REPORT_DIR:-/home/ec2-user/amazonqcli_lab/aws-arch-analysis/report}"
LOG_FILE="steampipe_database_collection.log"
ERROR_LOG="steampipe_database_errors.log"

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

# ë¡œê¹… í•¨ìˆ˜
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1" | tee -a "$LOG_FILE"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1" | tee -a "$LOG_FILE"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1" | tee -a "$LOG_FILE"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1" | tee -a "$ERROR_LOG"
}

log_rds() {
    echo -e "${PURPLE}[RDS]${NC} $1" | tee -a "$LOG_FILE"
}

log_nosql() {
    echo -e "${CYAN}[NoSQL]${NC} $1" | tee -a "$LOG_FILE"
}

# Steampipe ì¿¼ë¦¬ ì‹¤í–‰ í•¨ìˆ˜
execute_steampipe_query() {
    local description="$1"
    local query="$2"
    local output_file="$3"
    
    log_info "ìˆ˜ì§‘ ì¤‘: $description"
    
    if steampipe query "$query" --output json > "$output_file" 2>>"$ERROR_LOG"; then
        local file_size=$(stat -f%z "$output_file" 2>/dev/null || stat -c%s "$output_file" 2>/dev/null)
        if [ "$file_size" -gt 50 ]; then
            log_success "$description ì™„ë£Œ ($output_file, ${file_size} bytes)"
            return 0
        else
            log_warning "$description - ë°ì´í„° ì—†ìŒ ($output_file, ${file_size} bytes)"
            return 1
        fi
    else
        log_error "$description ì‹¤íŒ¨ - $output_file"
        return 1
    fi
}

# ë©”ì¸ ì‹¤í–‰ë¶€
main() {
    log_info "ğŸ—„ï¸ ì™„ì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (RDS, NoSQL, ë¶„ì„ ì„œë¹„ìŠ¤ í¬í•¨)"
    log_info "Region: $REGION"
    log_info "Report Directory: $REPORT_DIR"
    
    # ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ ìƒì„± ë° ì´ë™
    mkdir -p "$REPORT_DIR"
    cd "$REPORT_DIR" || exit 1
    
    # ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™”
    > "$LOG_FILE"
    > "$ERROR_LOG"
    
    # Steampipe ì„¤ì¹˜ í™•ì¸
    if ! command -v steampipe &> /dev/null; then
        log_error "Steampipeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        echo -e "${YELLOW}ğŸ’¡ Steampipe ì„¤ì¹˜ ë°©ë²•:${NC}"
        echo "sudo /bin/sh -c \"\$(curl -fsSL https://raw.githubusercontent.com/turbot/steampipe/main/install.sh)\""
        echo "steampipe plugin install aws"
        exit 1
    fi
    
    # AWS í”ŒëŸ¬ê·¸ì¸ í™•ì¸
    log_info "Steampipe AWS í”ŒëŸ¬ê·¸ì¸ í™•ì¸ ì¤‘..."
    if ! steampipe plugin list | grep -q "aws"; then
        log_warning "AWS í”ŒëŸ¬ê·¸ì¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘..."
        steampipe plugin install aws
    fi
    
    # ìˆ˜ì§‘ ì¹´ìš´í„°
    local success_count=0
    local total_count=0
    
    log_rds "ğŸ›ï¸ RDS ì¸ìŠ¤í„´ìŠ¤ ë° í´ëŸ¬ìŠ¤í„° ìˆ˜ì§‘ ì‹œì‘..."
    
    # RDS ê¸°ë³¸ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ë°°ì—´
    declare -a rds_queries=(
        "RDS DB ì¸ìŠ¤í„´ìŠ¤|select db_instance_identifier, db_instance_class, engine, engine_version, db_instance_status, allocated_storage, storage_type, storage_encrypted, multi_az, publicly_accessible, vpc_security_groups, db_subnet_group_name, backup_retention_period, preferred_backup_window, preferred_maintenance_window, auto_minor_version_upgrade, deletion_protection, tags from aws_rds_db_instance where region = '$REGION'|database_rds_instances.json"
        "RDS DB í´ëŸ¬ìŠ¤í„°|select db_cluster_identifier, engine, engine_version, database_name, db_cluster_members, vpc_security_groups, db_subnet_group_name, backup_retention_period, preferred_backup_window, preferred_maintenance_window, multi_az, storage_encrypted, kms_key_id, endpoint, reader_endpoint, status, deletion_protection, tags from aws_rds_db_cluster where region = '$REGION'|database_rds_clusters.json"
        "RDS ì„œë¸Œë„· ê·¸ë£¹|select db_subnet_group_name, db_subnet_group_description, vpc_id, subnet_group_status, subnets, tags from aws_rds_db_subnet_group where region = '$REGION'|database_rds_subnet_groups.json"
        "RDS íŒŒë¼ë¯¸í„° ê·¸ë£¹|select db_parameter_group_name, db_parameter_group_family, description, tags from aws_rds_db_parameter_group where region = '$REGION'|database_rds_parameter_groups.json"
        "RDS ìŠ¤ëƒ…ìƒ·|select db_snapshot_identifier, db_instance_identifier, snapshot_create_time, engine, allocated_storage, status, encrypted, kms_key_id, tags from aws_rds_db_snapshot where region = '$REGION'|database_rds_snapshots.json"
    )
    
    # RDS ì¿¼ë¦¬ ì‹¤í–‰
    for query_info in "${rds_queries[@]}"; do
        IFS='|' read -r description query output_file <<< "$query_info"
        ((total_count++))
        if execute_steampipe_query "$description" "$query" "$output_file"; then
            ((success_count++))
        fi
    done
    
    log_nosql "ğŸ”¥ DynamoDB ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘..."
    
    # DynamoDB ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ë°°ì—´
    declare -a dynamodb_queries=(
        "DynamoDB í…Œì´ë¸”|select name, table_status, creation_date_time, billing_mode_summary, provisioned_throughput, global_secondary_indexes, stream_specification, deletion_protection_enabled, tags from aws_dynamodb_table where region = '$REGION'|database_dynamodb_tables.json"
        "DynamoDB ë°±ì—…|select backup_name, backup_status, backup_type, backup_creation_date_time, table_name, backup_size_bytes from aws_dynamodb_backup where region = '$REGION'|database_dynamodb_backups.json"
    )
    
    # DynamoDB ì¿¼ë¦¬ ì‹¤í–‰
    for query_info in "${dynamodb_queries[@]}"; do
        IFS='|' read -r description query output_file <<< "$query_info"
        ((total_count++))
        if execute_steampipe_query "$description" "$query" "$output_file"; then
            ((success_count++))
        fi
    done
    
    log_nosql "âš¡ ElastiCache ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘..."
    
    # ElastiCache ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ë°°ì—´
    declare -a elasticache_queries=(
        "ElastiCache í´ëŸ¬ìŠ¤í„°|select cache_cluster_id, cache_node_type, engine, engine_version, cache_cluster_status, num_cache_nodes, preferred_availability_zone, cache_cluster_create_time, preferred_maintenance_window, auto_minor_version_upgrade, security_groups, replication_group_id from aws_elasticache_cluster where region = '$REGION'|database_elasticache_clusters.json"
        "ElastiCache ë³µì œ ê·¸ë£¹|select replication_group_id, description, status, member_clusters, automatic_failover, multi_az, cache_node_type, auth_token_enabled, transit_encryption_enabled, at_rest_encryption_enabled from aws_elasticache_replication_group where region = '$REGION'|database_elasticache_replication_groups.json"
    )
    
    # ElastiCache ì¿¼ë¦¬ ì‹¤í–‰
    for query_info in "${elasticache_queries[@]}"; do
        IFS='|' read -r description query output_file <<< "$query_info"
        ((total_count++))
        if execute_steampipe_query "$description" "$query" "$output_file"; then
            ((success_count++))
        fi
    done
    
    log_info "ğŸ¢ ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ì„œë¹„ìŠ¤ ìˆ˜ì§‘ ì‹œì‘..."
    
    # ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ë°°ì—´
    declare -a warehouse_queries=(
        "Redshift í´ëŸ¬ìŠ¤í„°|select cluster_identifier, node_type, cluster_status, master_username, db_name, endpoint, cluster_create_time, number_of_nodes, publicly_accessible, encrypted, vpc_id, tags from aws_redshift_cluster where region = '$REGION'|database_redshift_clusters.json"
        "OpenSearch ë„ë©”ì¸|select domain_name, elasticsearch_version, endpoint, processing, created, deleted, elasticsearch_cluster_config, ebs_options, vpc_options, encryption_at_rest_options, tags from aws_opensearch_domain where region = '$REGION'|database_opensearch_domains.json"
    )
    
    # ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰
    for query_info in "${warehouse_queries[@]}"; do
        IFS='|' read -r description query output_file <<< "$query_info"
        ((total_count++))
        if execute_steampipe_query "$description" "$query" "$output_file"; then
            ((success_count++))
        fi
    done
    
    log_info "ğŸš€ ë¹…ë°ì´í„° ì²˜ë¦¬ ì„œë¹„ìŠ¤ ìˆ˜ì§‘ ì‹œì‘..."
    
    # ë¹…ë°ì´í„° ì²˜ë¦¬ ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ë°°ì—´
    declare -a bigdata_queries=(
        "EMR í´ëŸ¬ìŠ¤í„°|select id, name, status, ec2_instance_attributes, log_uri, release_label, auto_terminate, termination_protected, applications, service_role, tags from aws_emr_cluster where region = '$REGION'|database_emr_clusters.json"
        "Kinesis ìŠ¤íŠ¸ë¦¼|select name, status, retention_period, shard_count, stream_creation_timestamp, tags from aws_kinesis_stream where region = '$REGION'|database_kinesis_streams.json"
        "Glue ë°ì´í„°ë² ì´ìŠ¤|select name, description, location_uri, create_time from aws_glue_catalog_database where region = '$REGION'|database_glue_databases.json"
        "Athena ì›Œí¬ê·¸ë£¹|select name, description, state, configuration, creation_time, tags from aws_athena_workgroup where region = '$REGION'|database_athena_workgroups.json"
    )
    
    # ë¹…ë°ì´í„° ì²˜ë¦¬ ì¿¼ë¦¬ ì‹¤í–‰
    for query_info in "${bigdata_queries[@]}"; do
        IFS='|' read -r description query output_file <<< "$query_info"
        ((total_count++))
        if execute_steampipe_query "$description" "$query" "$output_file"; then
            ((success_count++))
        fi
    done
    
    # ê²°ê³¼ ìš”ì•½
    log_success "ì™„ì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!"
    log_info "ì„±ê³µ: $success_count/$total_count"
    
    # íŒŒì¼ ëª©ë¡ ë° í¬ê¸° í‘œì‹œ
    echo -e "\n${BLUE}ğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡:${NC}"
    for file in database_*.json; do
        if [ -f "$file" ]; then
            size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null)
            if [ "$size" -gt 100 ]; then
                echo -e "${GREEN}âœ“ $file (${size} bytes)${NC}"
            else
                echo -e "${YELLOW}âš  $file (${size} bytes) - ë°ì´í„° ì—†ìŒ${NC}"
            fi
        fi
    done
    
    # ìˆ˜ì§‘ í†µê³„
    echo -e "\n${BLUE}ğŸ“Š ìˆ˜ì§‘ í†µê³„:${NC}"
    echo "ì´ ì¿¼ë¦¬ ìˆ˜: $total_count"
    echo "ì„±ê³µí•œ ì¿¼ë¦¬: $success_count"
    echo "ì‹¤íŒ¨í•œ ì¿¼ë¦¬: $((total_count - success_count))"
    
    # ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ í˜„í™©
    echo -e "\n${BLUE}ğŸ“‹ ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ í˜„í™©:${NC}"
    echo "ğŸ›ï¸  RDS ë¦¬ì†ŒìŠ¤: 5ê°œ"
    echo "ğŸ”¥ DynamoDB: 2ê°œ"
    echo "âš¡ ElastiCache: 2ê°œ"
    echo "ğŸ¢ ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤: 2ê°œ"
    echo "ğŸš€ ë¹…ë°ì´í„° ì²˜ë¦¬: 4ê°œ"
    echo "ğŸ“Š ì´ ë¦¬ì†ŒìŠ¤ íƒ€ì…: 15ê°œ"
    
    # ì˜¤ë¥˜ ë¡œê·¸ í™•ì¸
    if [ -s "$ERROR_LOG" ]; then
        log_warning "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. $ERROR_LOG íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."
        echo -e "\n${YELLOW}ìµœê·¼ ì˜¤ë¥˜ (ë§ˆì§€ë§‰ 5ì¤„):${NC}"
        tail -5 "$ERROR_LOG"
    fi
    
    # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
    echo -e "\n${YELLOW}ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:${NC}"
    echo "1. ìˆ˜ì§‘ëœ ì™„ì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸ ë¶„ì„ ì§„í–‰"
    echo "2. RDS ì¸ìŠ¤í„´ìŠ¤ ì„±ëŠ¥ ë° ë¹„ìš© ìµœì í™” ë¶„ì„"
    echo "3. DynamoDB í…Œì´ë¸” êµ¬ì„± ë° ì„±ëŠ¥ ê²€í† "
    echo "4. ElastiCache í´ëŸ¬ìŠ¤í„° ìµœì í™” ë¶„ì„"
    echo "5. ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ë° ë¶„ì„ ì„œë¹„ìŠ¤ í™œìš©ë„ ë¶„ì„"
    echo "6. ë¹…ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìµœì í™”"
    echo "7. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ë° ë³´ì•ˆ ì„¤ì • ì¢…í•© ê²€í† "
    
    log_info "ğŸ‰ ì™„ì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
}

# ë„ì›€ë§ í•¨ìˆ˜
show_help() {
    echo "ì‚¬ìš©ë²•: $0 [ì˜µì…˜]"
    echo ""
    echo "ì˜µì…˜:"
    echo "  -r, --region REGION    AWS ë¦¬ì „ ì„¤ì • (ê¸°ë³¸ê°’: ap-northeast-2)"
    echo "  -d, --dir DIRECTORY    ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ ì„¤ì •"
    echo "  -h, --help            ì´ ë„ì›€ë§ í‘œì‹œ"
    echo ""
    echo "í™˜ê²½ ë³€ìˆ˜:"
    echo "  AWS_REGION            AWS ë¦¬ì „ ì„¤ì •"
    echo "  REPORT_DIR            ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ ì„¤ì •"
    echo ""
    echo "í•„ìˆ˜ ìš”êµ¬ì‚¬í•­:"
    echo "  - Steampipe ì„¤ì¹˜"
    echo "  - AWS í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜: steampipe plugin install aws"
    echo ""
    echo "ì˜ˆì‹œ:"
    echo "  $0                                    # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰"
    echo "  $0 -r us-east-1                      # íŠ¹ì • ë¦¬ì „ìœ¼ë¡œ ì‹¤í–‰"
    echo "  $0 -d /custom/path                   # ì‚¬ìš©ì ì •ì˜ ë””ë ‰í† ë¦¬ë¡œ ì‹¤í–‰"
    echo "  AWS_REGION=eu-west-1 $0              # í™˜ê²½ ë³€ìˆ˜ë¡œ ë¦¬ì „ ì„¤ì •"
}

# ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
while [[ $# -gt 0 ]]; do
    case $1 in
        -r|--region)
            REGION="$2"
            shift 2
            ;;
        -d|--dir)
            REPORT_DIR="$2"
            shift 2
            ;;
        -h|--help)
            show_help
            exit 0
            ;;
        *)
            echo "ì•Œ ìˆ˜ ì—†ëŠ” ì˜µì…˜: $1"
            show_help
            exit 1
            ;;
    esac
done

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main "$@"
