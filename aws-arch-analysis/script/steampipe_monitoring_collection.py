#!/usr/bin/env python3
"""
AWS ëª¨ë‹ˆí„°ë§ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ì„œë¹„ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
CloudWatch, X-Ray, Config, Organizations, Service Catalog ë“± í¬ê´„ì  ìˆ˜ì§‘

ì‘ì„±ì: Amazon Q CLI Lab
ë²„ì „: 1.0
ìƒì„±ì¼: 2025-06-27
"""

import subprocess
import json
import os
import sys
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import time

class MonitoringDataCollector:
    def __init__(self):
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # ìŠ¤í¬ë¦½íŠ¸ì˜ ì‹¤ì œ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
        script_dir = Path(__file__).parent
        project_root = script_dir.parent.parent
        self.report_dir = project_root / "aws-arch-analysis" / "report"
        self.create_output_directory()
        
    def create_output_directory(self):
        """ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        try:
            self.report_dir.mkdir(parents=True, exist_ok=True)
            print(f"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {self.report_dir}")
        except Exception as e:
            print(f"âŒ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            sys.exit(1)

    def run_steampipe_query(self, service_name, query):
        """Steampipe ì¿¼ë¦¬ ì‹¤í–‰ ë° ê²°ê³¼ ì €ì¥"""
        try:
            print(f"ğŸ” {service_name} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # Steampipe ì¿¼ë¦¬ ì‹¤í–‰
            result = subprocess.run(
                ['steampipe', 'query', query, '--output', 'json'],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode == 0 and result.stdout.strip():
                # JSON íŒŒì‹± ì‹œë„
                try:
                    data = json.loads(result.stdout)
                    if data and len(data) > 0:
                        # íŒŒì¼ì— ì €ì¥
                        filename = self.report_dir / f"monitoring_{service_name.lower().replace(' ', '_')}.json"
                        with open(filename, 'w', encoding='utf-8') as f:
                            json.dump(data, f, indent=2, ensure_ascii=False, default=str)
                        
                        print(f"âœ… {service_name}: {len(data)}ê°œ í•­ëª© ìˆ˜ì§‘ ì™„ë£Œ")
                        return True, len(data)
                    else:
                        print(f"âš ï¸  {service_name}: ë°ì´í„° ì—†ìŒ")
                        return False, 0
                except json.JSONDecodeError as e:
                    print(f"âŒ {service_name}: JSON íŒŒì‹± ì˜¤ë¥˜ - {e}")
                    return False, 0
            else:
                error_msg = result.stderr.strip() if result.stderr else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
                print(f"âŒ {service_name}: ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨ - {error_msg}")
                return False, 0
                
        except subprocess.TimeoutExpired:
            print(f"â° {service_name}: ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ (60ì´ˆ)")
            return False, 0
        except Exception as e:
            print(f"âŒ {service_name}: ì˜ˆì™¸ ë°œìƒ - {e}")
            return False, 0

    def get_monitoring_queries(self):
        """ëª¨ë‹ˆí„°ë§ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ì„œë¹„ìŠ¤ ì¿¼ë¦¬ ì •ì˜ (ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸” ê¸°ë°˜)"""
        return {
            # CloudWatch ì•ŒëŒ (ì‹¤ì œ í…Œì´ë¸”ëª…: aws_cloudwatch_alarm)
            "CloudWatch Alarms": "select name, arn, alarm_description, state_value, metric_name, namespace, statistic, threshold, comparison_operator, evaluation_periods, datapoints_to_alarm, treat_missing_data, alarm_actions, ok_actions, insufficient_data_actions, region, account_id from aws_cloudwatch_alarm;",
            
            # CloudWatch ì´ë²¤íŠ¸ ê·œì¹™ (EventBridge)
            "CloudWatch Event Rules": "select name, arn, description, event_pattern, schedule_expression, state, role_arn, managed_by, event_bus_name, targets, tags, region, account_id from aws_cloudwatch_event_rule;",
            
            # CloudWatch Logs
            "CloudWatch Log Groups": "select name, arn, creation_time, retention_in_days, stored_bytes, metric_filter_count, kms_key_id, tags, region, account_id from aws_cloudwatch_log_group;",
            
            "CloudWatch Log Streams": "select log_group_name, name, arn, creation_time, first_event_time, last_event_time, last_ingestion_time, upload_sequence_token, stored_bytes, region, account_id from aws_cloudwatch_log_stream;",
            
            "CloudWatch Log Metric Filters": "select name, log_group_name, filter_pattern, metric_transformations, creation_time, region, account_id from aws_cloudwatch_log_metric_filter;",
            
            "CloudWatch Log Subscription Filters": "select name, log_group_name, filter_pattern, destination_arn, role_arn, distribution, creation_time, region, account_id from aws_cloudwatch_log_subscription_filter;",
            
            "CloudWatch Log Destinations": "select destination_name, arn, role_arn, target_arn, access_policy, creation_time, region, account_id from aws_cloudwatch_log_destination;",
            
            "CloudWatch Log Resource Policies": "select policy_name, policy_document, last_updated_time, region, account_id from aws_cloudwatch_log_resource_policy;",
            
            # CloudWatch ë©”íŠ¸ë¦­
            "CloudWatch Metrics": "select metric_name, namespace, dimensions, region, account_id from aws_cloudwatch_metric;",
            
            # CloudTrail
            "CloudTrail Trails": "select name, arn, s3_bucket_name, s3_key_prefix, include_global_service_events, is_multi_region_trail, home_region, trail_arn, log_file_validation_enabled, cloud_watch_logs_log_group_arn, cloud_watch_logs_role_arn, kms_key_id, has_custom_event_selectors, has_insight_selectors, is_organization_trail, is_logging, latest_delivery_time, latest_notification_time, start_logging_time, stop_logging_time, tags, region, account_id from aws_cloudtrail_trail;",
            
            "CloudTrail Event Data Stores": "select arn, name, status, advanced_event_selectors, multi_region_enabled, organization_enabled, retention_period, termination_protection_enabled, kms_key_id, created_timestamp, updated_timestamp, region, account_id from aws_cloudtrail_event_data_store;",
            
            "CloudTrail Channels": "select arn, name, source, destinations, region, account_id from aws_cloudtrail_channel;",
            
            # Config
            "Config Configuration Recorders": "select name, role_arn, recording_group, status, region, account_id from aws_config_configuration_recorder;",
            
            "Config Delivery Channels": "select name, s3_bucket_name, s3_key_prefix, sns_topic_arn, region, account_id from aws_config_delivery_channel;",
            
            "Config Rules": "select name, arn, rule_id, description, source, input_parameters, maximum_execution_frequency, state, created_by, region, account_id from aws_config_rule;",
            
            "Config Conformance Packs": "select name, arn, conformance_pack_id, delivery_s3_bucket, delivery_s3_key_prefix, conformance_pack_input_parameters, last_update_requested_time, created_by, region, account_id from aws_config_conformance_pack;",
            
            "Config Aggregate Authorizations": "select authorized_account_id, authorized_aws_region, creation_time, region, account_id from aws_config_aggregate_authorization;",
            
            "Config Retention Configurations": "select name, retention_period_in_days, region, account_id from aws_config_retention_configuration;",
            
            # Service Catalog
            "Service Catalog Portfolios": "select id, arn, display_name, description, provider_name, created_time, tags, region, account_id from aws_servicecatalog_portfolio;",
            
            "Service Catalog Products": "select product_id, name, owner, short_description, type, distributor, has_default_path, support_description, support_email, support_url, created_time, tags, region, account_id from aws_servicecatalog_product;",
            
            "Service Catalog Provisioned Products": "select name, arn, id, type, provisioning_artifact_id, product_id, user_arn, user_arn_session, status, status_message, created_time, last_updated_time, last_record_id, last_provisioning_record_id, last_successful_provisioning_record_id, tags, region, account_id from aws_servicecatalog_provisioned_product;",
            
            # Organizations (ê¶Œí•œ í•„ìš”)
            "Organizations Accounts": "select id, arn, email, name, status, joined_method, joined_timestamp, region, account_id from aws_organizations_account;",
            
            "Organizations Organizational Units": "select id, arn, name, parent_id, region, account_id from aws_organizations_organizational_unit;",
            
            "Organizations Policies": "select id, arn, name, description, type, aws_managed, content, region, account_id from aws_organizations_policy;",
            
            "Organizations Policy Targets": "select policy_id, target_id, target_type, region, account_id from aws_organizations_policy_target;",
            
            "Organizations Delegated Administrators": "select account_id, service_principal, delegation_enabled_date, region from aws_organizations_delegated_administrator;",
            
            "Organizations Root": "select id, arn, name, policy_types, region, account_id from aws_organizations_root;"
        }

    def collect_all_data(self):
        """ëª¨ë“  ëª¨ë‹ˆí„°ë§ ë°ì´í„° ë³‘ë ¬ ìˆ˜ì§‘"""
        queries = self.get_monitoring_queries()
        successful_collections = 0
        total_items = 0
        
        print(f"ğŸš€ ëª¨ë‹ˆí„°ë§ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ({len(queries)}ê°œ ì„œë¹„ìŠ¤)")
        print("=" * 80)
        
        start_time = time.time()
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ
        with ThreadPoolExecutor(max_workers=4) as executor:
            future_to_service = {
                executor.submit(self.run_steampipe_query, service, query): service 
                for service, query in queries.items()
            }
            
            for future in as_completed(future_to_service):
                service = future_to_service[future]
                try:
                    success, count = future.result()
                    if success:
                        successful_collections += 1
                        total_items += count
                except Exception as e:
                    print(f"âŒ {service}: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ - {e}")
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 80)
        print("ğŸ“Š ëª¨ë‹ˆí„°ë§ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"âœ… ì„±ê³µí•œ ìˆ˜ì§‘: {successful_collections}/{len(queries)} ({successful_collections/len(queries)*100:.1f}%)")
        print(f"ğŸ“¦ ì´ ìˆ˜ì§‘ í•­ëª©: {total_items:,}ê°œ")
        print(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.report_dir}")
        
        # ìˆ˜ì§‘ëœ íŒŒì¼ ëª©ë¡
        if successful_collections > 0:
            print(f"\nğŸ“‹ ìˆ˜ì§‘ëœ ë°ì´í„° íŒŒì¼:")
            try:
                files = sorted([f for f in self.report_dir.glob("monitoring_*.json")])
                for file_path in files:
                    file_size = file_path.stat().st_size
                    print(f"   â€¢ {file_path.name} ({file_size:,} bytes)")
            except Exception as e:
                print(f"   íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return successful_collections, total_items

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” AWS ëª¨ë‹ˆí„°ë§ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ì„œë¹„ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ê¸°")
    print("=" * 80)
    
    # Steampipe ì„¤ì¹˜ í™•ì¸
    try:
        result = subprocess.run(['steampipe', '--version'], capture_output=True, text=True)
        if result.returncode != 0:
            print("âŒ Steampipeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜ ë°©ë²•: https://steampipe.io/downloads")
            sys.exit(1)
        print(f"âœ… Steampipe ë²„ì „: {result.stdout.strip()}")
    except FileNotFoundError:
        print("âŒ Steampipeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PATHì— ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    # ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
    collector = MonitoringDataCollector()
    successful_collections, total_items = collector.collect_all_data()
    
    if successful_collections == 0:
        print("\nâš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. AWS ìê²© ì¦ëª…ê³¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    print(f"\nğŸ‰ ëª¨ë‹ˆí„°ë§ ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print(f"   python3 generate-monitoring-report.py")

if __name__ == "__main__":
    main()
